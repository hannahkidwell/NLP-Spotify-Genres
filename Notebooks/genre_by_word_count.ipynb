{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>song_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>category</th>\n",
       "      <th>category_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>genres</th>\n",
       "      <th>audio_ft_danceability</th>\n",
       "      <th>audio_ft_energy</th>\n",
       "      <th>...</th>\n",
       "      <th>audio_ft_acousticness</th>\n",
       "      <th>audio_ft_instrumentalness</th>\n",
       "      <th>audio_ft_liveness</th>\n",
       "      <th>audio_ft_valence</th>\n",
       "      <th>audio_ft_tempo</th>\n",
       "      <th>audio_ft_duration_ms</th>\n",
       "      <th>audio_ft_time_signature</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>filtered</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>willow</td>\n",
       "      <td>0lx2cLdOt3piJbcaXIV74f</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>06HL4z0CvFAxyc27GXpf02</td>\n",
       "      <td>pop</td>\n",
       "      <td>8</td>\n",
       "      <td>93</td>\n",
       "      <td>['dance', 'pop']</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8330</td>\n",
       "      <td>0.00179</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.529</td>\n",
       "      <td>81.112</td>\n",
       "      <td>214707.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Im like the water when your ship rolled in th...</td>\n",
       "      <td>['', 'im', 'like', 'water', 'ship', 'rolled', ...</td>\n",
       "      <td>(1, 'en')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stay Next To Me (with Chelsea Cutler)</td>\n",
       "      <td>6SGG5AxHShqSYiV9fCWpZz</td>\n",
       "      <td>Quinn XCII</td>\n",
       "      <td>3ApUX1o6oSz321MMECyIYd</td>\n",
       "      <td>pop</td>\n",
       "      <td>8</td>\n",
       "      <td>78</td>\n",
       "      <td>['indie', 'pop', 'electropop']</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0805</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.756</td>\n",
       "      <td>179.954</td>\n",
       "      <td>206046.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Didnt even wanna go out whyd you call me ? Iv...</td>\n",
       "      <td>['', 'didnt', 'even', 'wanna', 'go', 'whyd', '...</td>\n",
       "      <td>(1, 'en')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WITHOUT YOU</td>\n",
       "      <td>27OeeYzk6klgBh83TSvGMA</td>\n",
       "      <td>The Kid LAROI</td>\n",
       "      <td>2tIP7SsRs7vjIcLrU85W8J</td>\n",
       "      <td>pop</td>\n",
       "      <td>8</td>\n",
       "      <td>95</td>\n",
       "      <td>['australian']</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2130</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.467</td>\n",
       "      <td>93.005</td>\n",
       "      <td>161385.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>You cut out a piece of me and now I bleed int...</td>\n",
       "      <td>['', 'cut', 'piece', 'bleed', 'internally', 'l...</td>\n",
       "      <td>(1, 'en')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    song                 song_id  \\\n",
       "0                                 willow  0lx2cLdOt3piJbcaXIV74f   \n",
       "1  Stay Next To Me (with Chelsea Cutler)  6SGG5AxHShqSYiV9fCWpZz   \n",
       "2                            WITHOUT YOU  27OeeYzk6klgBh83TSvGMA   \n",
       "\n",
       "          artist               artist_id category  category_id  popularity  \\\n",
       "0   Taylor Swift  06HL4z0CvFAxyc27GXpf02      pop            8          93   \n",
       "1     Quinn XCII  3ApUX1o6oSz321MMECyIYd      pop            8          78   \n",
       "2  The Kid LAROI  2tIP7SsRs7vjIcLrU85W8J      pop            8          95   \n",
       "\n",
       "                           genres  audio_ft_danceability  audio_ft_energy  \\\n",
       "0                ['dance', 'pop']                  0.392            0.574   \n",
       "1  ['indie', 'pop', 'electropop']                  0.581            0.584   \n",
       "2                  ['australian']                  0.662            0.413   \n",
       "\n",
       "   ...  audio_ft_acousticness  audio_ft_instrumentalness  audio_ft_liveness  \\\n",
       "0  ...                 0.8330                    0.00179              0.145   \n",
       "1  ...                 0.0805                    0.00000              0.366   \n",
       "2  ...                 0.2130                    0.00000              0.134   \n",
       "\n",
       "   audio_ft_valence  audio_ft_tempo  audio_ft_duration_ms  \\\n",
       "0             0.529          81.112              214707.0   \n",
       "1             0.756         179.954              206046.0   \n",
       "2             0.467          93.005              161385.0   \n",
       "\n",
       "   audio_ft_time_signature                                             lyrics  \\\n",
       "0                      4.0   Im like the water when your ship rolled in th...   \n",
       "1                      4.0   Didnt even wanna go out whyd you call me ? Iv...   \n",
       "2                      4.0   You cut out a piece of me and now I bleed int...   \n",
       "\n",
       "                                            filtered   language  \n",
       "0  ['', 'im', 'like', 'water', 'ship', 'rolled', ...  (1, 'en')  \n",
       "1  ['', 'didnt', 'even', 'wanna', 'go', 'whyd', '...  (1, 'en')  \n",
       "2  ['', 'cut', 'piece', 'bleed', 'internally', 'l...  (1, 'en')  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame from CSV file\n",
    "nlp_df = pd.read_csv('../Data/nlp_df.csv')\n",
    "nlp_df = nlp_df.drop(['non_alpha_words'], axis=1)\n",
    "nlp_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 1.5752971172332764 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36234"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of all words, word counts, unique word counts, and filtered words\n",
    "t0 = time.time()\n",
    "words_list = []\n",
    "word_counts = []\n",
    "unique_word_counts = []\n",
    "filtered_words_list = []\n",
    "for index, row in nlp_df.iterrows():\n",
    "    filtered_words = row['filtered']\n",
    "    filtered_words = filtered_words.replace(',', '').replace(\"'\", '')\n",
    "    filtered_words = filtered_words.replace('[', '').replace(']', '')\n",
    "    filtered_words = filtered_words.replace('#', '').replace('&nbsp', '')\n",
    "    filtered_words = filtered_words.replace('?', '? ').replace(',', '')\n",
    "    filtered_words = filtered_words.replace('/', ' ')\n",
    "    filtered_words = filtered_words.replace('\\\\u200a', '').replace('\\\\u200b', '')\n",
    "    filtered_words = filtered_words.replace('\\\\u2063', '').replace('\\u202f', '')\n",
    "    filtered_words = filtered_words.replace('\\\\u2028', ' ').replace('\\\\u2008', ' ')\n",
    "    while ('\\\\u200e' in filtered_words) or ('\\\\xa0' in filtered_words):\n",
    "        filtered_words = filtered_words.replace('\\\\u200e', '')\n",
    "        filtered_words = filtered_words.replace('\\\\xa0', '')\n",
    "    filtered_words_list.append(filtered_words)\n",
    "    words = filtered_words.strip().split(' ')\n",
    "    word_counts.append(len(words))\n",
    "    unique_words = list(set(words))\n",
    "    unique_word_counts.append(len(unique_words))\n",
    "    words_list.extend(unique_words)\n",
    "word_columns = list(set(words_list))\n",
    "t1 = time.time()\n",
    "print(f'Run time: {t1-t0} seconds')\n",
    "len(word_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>song_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>category</th>\n",
       "      <th>category_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>genres</th>\n",
       "      <th>audio_ft_danceability</th>\n",
       "      <th>audio_ft_energy</th>\n",
       "      <th>...</th>\n",
       "      <th>audio_ft_liveness</th>\n",
       "      <th>audio_ft_valence</th>\n",
       "      <th>audio_ft_tempo</th>\n",
       "      <th>audio_ft_duration_ms</th>\n",
       "      <th>audio_ft_time_signature</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>filtered</th>\n",
       "      <th>language</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>willow</td>\n",
       "      <td>0lx2cLdOt3piJbcaXIV74f</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>06HL4z0CvFAxyc27GXpf02</td>\n",
       "      <td>pop</td>\n",
       "      <td>8</td>\n",
       "      <td>93</td>\n",
       "      <td>['dance', 'pop']</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.529</td>\n",
       "      <td>81.112</td>\n",
       "      <td>214707.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Im like the water when your ship rolled in th...</td>\n",
       "      <td>im like water ship rolled night rough surface...</td>\n",
       "      <td>(1, 'en')</td>\n",
       "      <td>227</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     song                 song_id        artist               artist_id  \\\n",
       "0  willow  0lx2cLdOt3piJbcaXIV74f  Taylor Swift  06HL4z0CvFAxyc27GXpf02   \n",
       "\n",
       "  category  category_id  popularity            genres  audio_ft_danceability  \\\n",
       "0      pop            8          93  ['dance', 'pop']                  0.392   \n",
       "\n",
       "   audio_ft_energy  ...  audio_ft_liveness  audio_ft_valence  audio_ft_tempo  \\\n",
       "0            0.574  ...              0.145             0.529          81.112   \n",
       "\n",
       "   audio_ft_duration_ms  audio_ft_time_signature  \\\n",
       "0              214707.0                      4.0   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0   Im like the water when your ship rolled in th...   \n",
       "\n",
       "                                            filtered   language  word_count  \\\n",
       "0   im like water ship rolled night rough surface...  (1, 'en')         227   \n",
       "\n",
       "   unique_word_count  \n",
       "0                 87  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add word_count and unique_word_count columns and replace the filtered column\n",
    "nlp_df['word_count'] = word_counts\n",
    "nlp_df['unique_word_count'] = unique_word_counts\n",
    "nlp_df['filtered'] = filtered_words_list\n",
    "nlp_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8041"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove songs with less than 25 unique words\n",
    "nlp_df = nlp_df[nlp_df['unique_word_count']>=25]\n",
    "len(nlp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine word counts by genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the language column\n",
    "nlp_df = nlp_df.drop('language', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8031"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop songs with incorrect lyrics from the DataFrame\n",
    "nlp_df = nlp_df[(nlp_df['unique_word_count']!=3878) & (nlp_df['unique_word_count']!=1153)]\n",
    "nlp_df = nlp_df[(nlp_df['unique_word_count']!=1000) & (nlp_df['unique_word_count']!=880)]\n",
    "nlp_df = nlp_df[(nlp_df['unique_word_count']!=842) & (nlp_df['unique_word_count']!=607)]\n",
    "nlp_df = nlp_df[(nlp_df['unique_word_count']!=569) & (nlp_df['word_count']!=1383)]\n",
    "len(nlp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the distribution of unique word counts for each cateogry\n",
    "word_distributions = {}\n",
    "blues_unique_words = nlp_df[nlp_df['category']=='blues']['word_count'].describe()\n",
    "word_distributions['blues'] = blues_unique_words\n",
    "\n",
    "classical_unique_words = nlp_df[nlp_df['category']=='classical']['word_count'].describe()\n",
    "word_distributions['classical'] = classical_unique_words\n",
    "\n",
    "country_unique_words = nlp_df[nlp_df['category']=='country']['word_count'].describe()\n",
    "word_distributions['country'] = country_unique_words\n",
    "\n",
    "funk_unique_words = nlp_df[nlp_df['category']=='funk']['word_count'].describe()\n",
    "word_distributions['funk'] = funk_unique_words\n",
    "\n",
    "hiphop_unique_words = nlp_df[nlp_df['category']=='hiphop']['word_count'].describe()\n",
    "word_distributions['hiphop'] = hiphop_unique_words\n",
    "\n",
    "indie_alt_unique_words = nlp_df[nlp_df['category']=='indie_alt']['word_count'].describe()\n",
    "word_distributions['indie_alt'] = indie_alt_unique_words\n",
    "\n",
    "jazz_unique_words = nlp_df[nlp_df['category']=='jazz']['word_count'].describe()\n",
    "word_distributions['jazz'] = jazz_unique_words\n",
    "\n",
    "metal_unique_words = nlp_df[nlp_df['category']=='metal']['word_count'].describe()\n",
    "word_distributions['metal'] = metal_unique_words\n",
    "\n",
    "pop_unique_words = nlp_df[nlp_df['category']=='pop']['word_count'].describe()\n",
    "word_distributions['pop'] = pop_unique_words\n",
    "\n",
    "punk_unique_words = nlp_df[nlp_df['category']=='punk']['word_count'].describe()\n",
    "word_distributions['punk'] = punk_unique_words\n",
    "\n",
    "rnb_unique_words = nlp_df[nlp_df['category']=='rnb']['word_count'].describe()\n",
    "word_distributions['rnb'] = rnb_unique_words\n",
    "\n",
    "rock_unique_words = nlp_df[nlp_df['category']=='rock']['word_count'].describe()\n",
    "word_distributions['rock'] = rock_unique_words\n",
    "\n",
    "romance_unique_words = nlp_df[nlp_df['category']=='romance']['word_count'].describe()\n",
    "word_distributions['romance'] = romance_unique_words\n",
    "\n",
    "soul_unique_words = nlp_df[nlp_df['category']=='soul']['word_count'].describe()\n",
    "word_distributions['soul'] = soul_unique_words\n",
    "len(word_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blues': count    424.000000\n",
       " mean     119.740566\n",
       " std       47.975256\n",
       " min       36.000000\n",
       " 25%       84.000000\n",
       " 50%      111.500000\n",
       " 75%      147.000000\n",
       " max      364.000000\n",
       " Name: word_count, dtype: float64,\n",
       " 'classical': count     93.000000\n",
       " mean     150.860215\n",
       " std      116.015328\n",
       " min       28.000000\n",
       " 25%       81.000000\n",
       " 50%      123.000000\n",
       " 75%      183.000000\n",
       " max      823.000000\n",
       " Name: word_count, dtype: float64,\n",
       " 'country': count    1257.000000\n",
       " mean      166.240255\n",
       " std        53.697886\n",
       " min        30.000000\n",
       " 25%       131.000000\n",
       " 50%       166.000000\n",
       " 75%       197.000000\n",
       " max       452.000000\n",
       " Name: word_count, dtype: float64,\n",
       " 'funk': count    282.000000\n",
       " mean     202.886525\n",
       " std      100.706656\n",
       " min       40.000000\n",
       " 25%      128.250000\n",
       " 50%      188.500000\n",
       " 75%      251.500000\n",
       " max      583.000000\n",
       " Name: word_count, dtype: float64,\n",
       " 'hiphop': count    680.000000\n",
       " mean     352.647059\n",
       " std      124.737895\n",
       " min       59.000000\n",
       " 25%      265.000000\n",
       " 50%      343.000000\n",
       " 75%      431.250000\n",
       " max      909.000000\n",
       " Name: word_count, dtype: float64,\n",
       " 'indie_alt': count    660.000000\n",
       " mean     141.339394\n",
       " std       59.928308\n",
       " min       34.000000\n",
       " 25%       99.000000\n",
       " 50%      132.000000\n",
       " 75%      170.000000\n",
       " max      469.000000\n",
       " Name: word_count, dtype: float64,\n",
       " 'jazz': count    198.000000\n",
       " mean     123.601010\n",
       " std       79.526948\n",
       " min       32.000000\n",
       " 25%       76.000000\n",
       " 50%      107.000000\n",
       " 75%      144.000000\n",
       " max      566.000000\n",
       " Name: word_count, dtype: float64,\n",
       " 'metal': count    898.000000\n",
       " mean     146.500000\n",
       " std       62.602518\n",
       " min       30.000000\n",
       " 25%      103.000000\n",
       " 50%      136.000000\n",
       " 75%      176.750000\n",
       " max      485.000000\n",
       " Name: word_count, dtype: float64,\n",
       " 'pop': count    693.000000\n",
       " mean     192.499278\n",
       " std       80.097008\n",
       " min       36.000000\n",
       " 25%      145.000000\n",
       " 50%      181.000000\n",
       " 75%      224.000000\n",
       " max      815.000000\n",
       " Name: word_count, dtype: float64,\n",
       " 'punk': count    569.000000\n",
       " mean     154.729350\n",
       " std       59.161844\n",
       " min       36.000000\n",
       " 25%      114.000000\n",
       " 50%      148.000000\n",
       " 75%      190.000000\n",
       " max      562.000000\n",
       " Name: word_count, dtype: float64,\n",
       " 'rnb': count    362.000000\n",
       " mean     232.483425\n",
       " std       93.733435\n",
       " min       60.000000\n",
       " 25%      167.250000\n",
       " 50%      215.500000\n",
       " 75%      287.750000\n",
       " max      658.000000\n",
       " Name: word_count, dtype: float64,\n",
       " 'rock': count    1225.000000\n",
       " mean      157.457959\n",
       " std        61.944011\n",
       " min        26.000000\n",
       " 25%       117.000000\n",
       " 50%       149.000000\n",
       " 75%       190.000000\n",
       " max       528.000000\n",
       " Name: word_count, dtype: float64,\n",
       " 'romance': count    279.000000\n",
       " mean     144.702509\n",
       " std       59.670929\n",
       " min       38.000000\n",
       " 25%      104.000000\n",
       " 50%      138.000000\n",
       " 75%      172.000000\n",
       " max      428.000000\n",
       " Name: word_count, dtype: float64,\n",
       " 'soul': count    411.000000\n",
       " mean     180.978102\n",
       " std       82.099951\n",
       " min       44.000000\n",
       " 25%      123.000000\n",
       " 50%      166.000000\n",
       " 75%      226.000000\n",
       " max      775.000000\n",
       " Name: word_count, dtype: float64}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the distributions for each genre\n",
    "word_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hiphop': 352.6470588235294,\n",
       " 'rnb': 232.48342541436463,\n",
       " 'funk': 202.88652482269504,\n",
       " 'pop': 192.4992784992785,\n",
       " 'soul': 180.97810218978103,\n",
       " 'country': 166.24025457438344,\n",
       " 'rock': 157.45795918367347,\n",
       " 'punk': 154.72934973637962,\n",
       " 'classical': 150.86021505376345,\n",
       " 'metal': 146.5,\n",
       " 'romance': 144.70250896057348,\n",
       " 'indie_alt': 141.33939393939394,\n",
       " 'jazz': 123.6010101010101,\n",
       " 'blues': 119.74056603773585}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary of mean word distributions\n",
    "categories = list(word_distributions.keys())\n",
    "means = []\n",
    "for category in word_distributions:\n",
    "    means.append(word_distributions[category]['mean'])\n",
    "mean_unique_word_counts = dict(zip(categories, means))\n",
    "mean_unique_word_counts = dict(sorted(mean_unique_word_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "mean_unique_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song with the most words:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>category</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>Rap God</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>hiphop</td>\n",
       "      <td>Look I was gonna go easy on you not to hurt y...</td>\n",
       "      <td>909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         song  artist category  \\\n",
       "1351  Rap God  Eminem   hiphop   \n",
       "\n",
       "                                                 lyrics  word_count  \n",
       "1351   Look I was gonna go easy on you not to hurt y...         909  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song with the least words:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>category</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>Golf Hill Drive</td>\n",
       "      <td>Boys Life</td>\n",
       "      <td>rock</td>\n",
       "      <td>Stuck in this life thats not my own And whoeve...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 song     artist category  \\\n",
       "2547  Golf Hill Drive  Boys Life     rock   \n",
       "\n",
       "                                                 lyrics  word_count  \n",
       "2547  Stuck in this life thats not my own And whoeve...          26  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find songs with the highest and lowest word counts\n",
    "print('Song with the most words:')\n",
    "display(nlp_df[nlp_df['word_count']==max(nlp_df['word_count'])][['song', 'artist', 'category', 'lyrics', 'word_count']])\n",
    "\n",
    "print('Song with the least words:')\n",
    "display(nlp_df[nlp_df['word_count']==min(nlp_df['word_count'])][['song', 'artist', 'category', 'lyrics', 'word_count']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blues</th>\n",
       "      <td>424.0</td>\n",
       "      <td>119.740566</td>\n",
       "      <td>47.975256</td>\n",
       "      <td>36.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>111.5</td>\n",
       "      <td>147.00</td>\n",
       "      <td>364.0</td>\n",
       "      <td>328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classical</th>\n",
       "      <td>93.0</td>\n",
       "      <td>150.860215</td>\n",
       "      <td>116.015328</td>\n",
       "      <td>28.0</td>\n",
       "      <td>81.00</td>\n",
       "      <td>123.0</td>\n",
       "      <td>183.00</td>\n",
       "      <td>823.0</td>\n",
       "      <td>795.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>166.240255</td>\n",
       "      <td>53.697886</td>\n",
       "      <td>30.0</td>\n",
       "      <td>131.00</td>\n",
       "      <td>166.0</td>\n",
       "      <td>197.00</td>\n",
       "      <td>452.0</td>\n",
       "      <td>422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funk</th>\n",
       "      <td>282.0</td>\n",
       "      <td>202.886525</td>\n",
       "      <td>100.706656</td>\n",
       "      <td>40.0</td>\n",
       "      <td>128.25</td>\n",
       "      <td>188.5</td>\n",
       "      <td>251.50</td>\n",
       "      <td>583.0</td>\n",
       "      <td>543.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hiphop</th>\n",
       "      <td>680.0</td>\n",
       "      <td>352.647059</td>\n",
       "      <td>124.737895</td>\n",
       "      <td>59.0</td>\n",
       "      <td>265.00</td>\n",
       "      <td>343.0</td>\n",
       "      <td>431.25</td>\n",
       "      <td>909.0</td>\n",
       "      <td>850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indie_alt</th>\n",
       "      <td>660.0</td>\n",
       "      <td>141.339394</td>\n",
       "      <td>59.928308</td>\n",
       "      <td>34.0</td>\n",
       "      <td>99.00</td>\n",
       "      <td>132.0</td>\n",
       "      <td>170.00</td>\n",
       "      <td>469.0</td>\n",
       "      <td>435.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jazz</th>\n",
       "      <td>198.0</td>\n",
       "      <td>123.601010</td>\n",
       "      <td>79.526948</td>\n",
       "      <td>32.0</td>\n",
       "      <td>76.00</td>\n",
       "      <td>107.0</td>\n",
       "      <td>144.00</td>\n",
       "      <td>566.0</td>\n",
       "      <td>534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metal</th>\n",
       "      <td>898.0</td>\n",
       "      <td>146.500000</td>\n",
       "      <td>62.602518</td>\n",
       "      <td>30.0</td>\n",
       "      <td>103.00</td>\n",
       "      <td>136.0</td>\n",
       "      <td>176.75</td>\n",
       "      <td>485.0</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop</th>\n",
       "      <td>693.0</td>\n",
       "      <td>192.499278</td>\n",
       "      <td>80.097008</td>\n",
       "      <td>36.0</td>\n",
       "      <td>145.00</td>\n",
       "      <td>181.0</td>\n",
       "      <td>224.00</td>\n",
       "      <td>815.0</td>\n",
       "      <td>779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>punk</th>\n",
       "      <td>569.0</td>\n",
       "      <td>154.729350</td>\n",
       "      <td>59.161844</td>\n",
       "      <td>36.0</td>\n",
       "      <td>114.00</td>\n",
       "      <td>148.0</td>\n",
       "      <td>190.00</td>\n",
       "      <td>562.0</td>\n",
       "      <td>526.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnb</th>\n",
       "      <td>362.0</td>\n",
       "      <td>232.483425</td>\n",
       "      <td>93.733435</td>\n",
       "      <td>60.0</td>\n",
       "      <td>167.25</td>\n",
       "      <td>215.5</td>\n",
       "      <td>287.75</td>\n",
       "      <td>658.0</td>\n",
       "      <td>598.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rock</th>\n",
       "      <td>1225.0</td>\n",
       "      <td>157.457959</td>\n",
       "      <td>61.944011</td>\n",
       "      <td>26.0</td>\n",
       "      <td>117.00</td>\n",
       "      <td>149.0</td>\n",
       "      <td>190.00</td>\n",
       "      <td>528.0</td>\n",
       "      <td>502.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romance</th>\n",
       "      <td>279.0</td>\n",
       "      <td>144.702509</td>\n",
       "      <td>59.670929</td>\n",
       "      <td>38.0</td>\n",
       "      <td>104.00</td>\n",
       "      <td>138.0</td>\n",
       "      <td>172.00</td>\n",
       "      <td>428.0</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soul</th>\n",
       "      <td>411.0</td>\n",
       "      <td>180.978102</td>\n",
       "      <td>82.099951</td>\n",
       "      <td>44.0</td>\n",
       "      <td>123.00</td>\n",
       "      <td>166.0</td>\n",
       "      <td>226.00</td>\n",
       "      <td>775.0</td>\n",
       "      <td>731.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count        mean         std   min     25%    50%     75%    max  \\\n",
       "blues       424.0  119.740566   47.975256  36.0   84.00  111.5  147.00  364.0   \n",
       "classical    93.0  150.860215  116.015328  28.0   81.00  123.0  183.00  823.0   \n",
       "country    1257.0  166.240255   53.697886  30.0  131.00  166.0  197.00  452.0   \n",
       "funk        282.0  202.886525  100.706656  40.0  128.25  188.5  251.50  583.0   \n",
       "hiphop      680.0  352.647059  124.737895  59.0  265.00  343.0  431.25  909.0   \n",
       "indie_alt   660.0  141.339394   59.928308  34.0   99.00  132.0  170.00  469.0   \n",
       "jazz        198.0  123.601010   79.526948  32.0   76.00  107.0  144.00  566.0   \n",
       "metal       898.0  146.500000   62.602518  30.0  103.00  136.0  176.75  485.0   \n",
       "pop         693.0  192.499278   80.097008  36.0  145.00  181.0  224.00  815.0   \n",
       "punk        569.0  154.729350   59.161844  36.0  114.00  148.0  190.00  562.0   \n",
       "rnb         362.0  232.483425   93.733435  60.0  167.25  215.5  287.75  658.0   \n",
       "rock       1225.0  157.457959   61.944011  26.0  117.00  149.0  190.00  528.0   \n",
       "romance     279.0  144.702509   59.670929  38.0  104.00  138.0  172.00  428.0   \n",
       "soul        411.0  180.978102   82.099951  44.0  123.00  166.0  226.00  775.0   \n",
       "\n",
       "           range  \n",
       "blues      328.0  \n",
       "classical  795.0  \n",
       "country    422.0  \n",
       "funk       543.0  \n",
       "hiphop     850.0  \n",
       "indie_alt  435.0  \n",
       "jazz       534.0  \n",
       "metal      455.0  \n",
       "pop        779.0  \n",
       "punk       526.0  \n",
       "rnb        598.0  \n",
       "rock       502.0  \n",
       "romance    390.0  \n",
       "soul       731.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame of word count distributions\n",
    "ranges = []\n",
    "for category in word_distributions:\n",
    "    ranges.append(word_distributions[category]['max'] - word_distributions[category]['min'])\n",
    "\n",
    "columns = ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'range']\n",
    "df_rows = []\n",
    "for index, category in enumerate(word_distributions):\n",
    "    distribution = list(word_distributions[category])\n",
    "    distribution.extend([ranges[index]])\n",
    "    df_rows.append(distribution)\n",
    "word_count_df = pd.DataFrame(df_rows, index=list(word_distributions.keys()), columns=columns)\n",
    "word_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV\n",
    "word_count_df.to_csv('../Data/Analysis/word_count.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions about word distributions by genre\n",
    "- The hiphop genre has the highest mean word count of 353 words\n",
    "- The blues genre has the lowest mean word count of 120 words\n",
    "- Genres with the highest average word counts:\n",
    "    - Hiphop: 353 words\n",
    "    - R&B: 232 words\n",
    "    - Funk: 203 words\n",
    "- Genres with the lowest average word counts:\n",
    "    - Blues: 120 words\n",
    "    - Jazz: 124 words\n",
    "    - Indie-alt: 141 words\n",
    "- The song with the highest word count is in the hiphop category:\n",
    "    - Song name: Rap God \n",
    "    - Artist: Eminem\n",
    "    - Word count: 909 words\n",
    "- The song with the lowest word count is in the rock category:\n",
    "    - Song name: Golf Hill Drive\n",
    "    - Artist: Boys Life\n",
    "    - Word count: 26 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine unique word counts by genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the distribution of unique word counts for each cateogry\n",
    "unique_word_distributions = {}\n",
    "blues_unique_words = nlp_df[nlp_df['category']=='blues']['unique_word_count'].describe()\n",
    "unique_word_distributions['blues'] = blues_unique_words\n",
    "\n",
    "classical_unique_words = nlp_df[nlp_df['category']=='classical']['unique_word_count'].describe()\n",
    "unique_word_distributions['classical'] = classical_unique_words\n",
    "\n",
    "country_unique_words = nlp_df[nlp_df['category']=='country']['unique_word_count'].describe()\n",
    "unique_word_distributions['country'] = country_unique_words\n",
    "\n",
    "funk_unique_words = nlp_df[nlp_df['category']=='funk']['unique_word_count'].describe()\n",
    "unique_word_distributions['funk'] = funk_unique_words\n",
    "\n",
    "hiphop_unique_words = nlp_df[nlp_df['category']=='hiphop']['unique_word_count'].describe()\n",
    "unique_word_distributions['hiphop'] = hiphop_unique_words\n",
    "\n",
    "indie_alt_unique_words = nlp_df[nlp_df['category']=='indie_alt']['unique_word_count'].describe()\n",
    "unique_word_distributions['indie_alt'] = indie_alt_unique_words\n",
    "\n",
    "jazz_unique_words = nlp_df[nlp_df['category']=='jazz']['unique_word_count'].describe()\n",
    "unique_word_distributions['jazz'] = jazz_unique_words\n",
    "\n",
    "metal_unique_words = nlp_df[nlp_df['category']=='metal']['unique_word_count'].describe()\n",
    "unique_word_distributions['metal'] = metal_unique_words\n",
    "\n",
    "pop_unique_words = nlp_df[nlp_df['category']=='pop']['unique_word_count'].describe()\n",
    "unique_word_distributions['pop'] = pop_unique_words\n",
    "\n",
    "punk_unique_words = nlp_df[nlp_df['category']=='punk']['unique_word_count'].describe()\n",
    "unique_word_distributions['punk'] = punk_unique_words\n",
    "\n",
    "rnb_unique_words = nlp_df[nlp_df['category']=='rnb']['unique_word_count'].describe()\n",
    "unique_word_distributions['rnb'] = rnb_unique_words\n",
    "\n",
    "rock_unique_words = nlp_df[nlp_df['category']=='rock']['unique_word_count'].describe()\n",
    "unique_word_distributions['rock'] = rock_unique_words\n",
    "\n",
    "romance_unique_words = nlp_df[nlp_df['category']=='romance']['unique_word_count'].describe()\n",
    "unique_word_distributions['romance'] = romance_unique_words\n",
    "\n",
    "soul_unique_words = nlp_df[nlp_df['category']=='soul']['unique_word_count'].describe()\n",
    "unique_word_distributions['soul'] = soul_unique_words\n",
    "len(unique_word_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blues': count    424.000000\n",
       " mean      53.707547\n",
       " std       19.685094\n",
       " min       25.000000\n",
       " 25%       39.000000\n",
       " 50%       51.000000\n",
       " 75%       64.000000\n",
       " max      197.000000\n",
       " Name: unique_word_count, dtype: float64,\n",
       " 'classical': count     93.000000\n",
       " mean      78.236559\n",
       " std       64.720872\n",
       " min       25.000000\n",
       " 25%       44.000000\n",
       " 50%       61.000000\n",
       " 75%       90.000000\n",
       " max      503.000000\n",
       " Name: unique_word_count, dtype: float64,\n",
       " 'country': count    1257.000000\n",
       " mean       74.820207\n",
       " std        24.007187\n",
       " min        25.000000\n",
       " 25%        60.000000\n",
       " 50%        73.000000\n",
       " 75%        87.000000\n",
       " max       264.000000\n",
       " Name: unique_word_count, dtype: float64,\n",
       " 'funk': count    282.000000\n",
       " mean      73.092199\n",
       " std       38.428545\n",
       " min       26.000000\n",
       " 25%       50.000000\n",
       " 50%       63.000000\n",
       " 75%       83.750000\n",
       " max      257.000000\n",
       " Name: unique_word_count, dtype: float64,\n",
       " 'hiphop': count    680.000000\n",
       " mean     173.770588\n",
       " std       74.667690\n",
       " min       28.000000\n",
       " 25%      123.000000\n",
       " 50%      166.000000\n",
       " 75%      216.000000\n",
       " max      544.000000\n",
       " Name: unique_word_count, dtype: float64,\n",
       " 'indie_alt': count    660.000000\n",
       " mean      57.984848\n",
       " std       24.801422\n",
       " min       25.000000\n",
       " 25%       41.000000\n",
       " 50%       54.000000\n",
       " 75%       68.000000\n",
       " max      253.000000\n",
       " Name: unique_word_count, dtype: float64,\n",
       " 'jazz': count    198.000000\n",
       " mean      60.656566\n",
       " std       42.117834\n",
       " min       26.000000\n",
       " 25%       39.000000\n",
       " 50%       51.000000\n",
       " 75%       65.000000\n",
       " max      349.000000\n",
       " Name: unique_word_count, dtype: float64,\n",
       " 'metal': count    898.000000\n",
       " mean      69.175947\n",
       " std       26.775840\n",
       " min       25.000000\n",
       " 25%       51.000000\n",
       " 50%       64.000000\n",
       " 75%       82.000000\n",
       " max      220.000000\n",
       " Name: unique_word_count, dtype: float64,\n",
       " 'pop': count    693.000000\n",
       " mean      69.748918\n",
       " std       30.938040\n",
       " min       26.000000\n",
       " 25%       53.000000\n",
       " 50%       64.000000\n",
       " 75%       78.000000\n",
       " max      360.000000\n",
       " Name: unique_word_count, dtype: float64,\n",
       " 'punk': count    569.000000\n",
       " mean      70.070299\n",
       " std       30.317486\n",
       " min       25.000000\n",
       " 25%       51.000000\n",
       " 50%       66.000000\n",
       " 75%       82.000000\n",
       " max      315.000000\n",
       " Name: unique_word_count, dtype: float64,\n",
       " 'rnb': count    362.000000\n",
       " mean      85.185083\n",
       " std       33.778347\n",
       " min       31.000000\n",
       " 25%       61.000000\n",
       " 50%       79.000000\n",
       " 75%      100.000000\n",
       " max      220.000000\n",
       " Name: unique_word_count, dtype: float64,\n",
       " 'rock': count    1225.000000\n",
       " mean       63.481633\n",
       " std        25.927782\n",
       " min        25.000000\n",
       " 25%        48.000000\n",
       " 50%        59.000000\n",
       " 75%        74.000000\n",
       " max       308.000000\n",
       " Name: unique_word_count, dtype: float64,\n",
       " 'romance': count    279.000000\n",
       " mean      59.559140\n",
       " std       21.160127\n",
       " min       25.000000\n",
       " 25%       45.500000\n",
       " 50%       57.000000\n",
       " 75%       71.000000\n",
       " max      166.000000\n",
       " Name: unique_word_count, dtype: float64,\n",
       " 'soul': count    411.000000\n",
       " mean      70.644769\n",
       " std       30.872600\n",
       " min       26.000000\n",
       " 25%       50.000000\n",
       " 50%       64.000000\n",
       " 75%       82.000000\n",
       " max      238.000000\n",
       " Name: unique_word_count, dtype: float64}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the distributions for each genre\n",
    "unique_word_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hiphop': 173.77058823529413,\n",
       " 'rnb': 85.18508287292818,\n",
       " 'classical': 78.23655913978494,\n",
       " 'country': 74.82020684168656,\n",
       " 'funk': 73.09219858156028,\n",
       " 'soul': 70.64476885644768,\n",
       " 'punk': 70.07029876977153,\n",
       " 'pop': 69.74891774891775,\n",
       " 'metal': 69.17594654788418,\n",
       " 'rock': 63.481632653061226,\n",
       " 'jazz': 60.656565656565654,\n",
       " 'romance': 59.55913978494624,\n",
       " 'indie_alt': 57.984848484848484,\n",
       " 'blues': 53.70754716981132}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary of mean unique word distributions\n",
    "categories = list(unique_word_distributions.keys())\n",
    "means = []\n",
    "for category in unique_word_distributions:\n",
    "    means.append(unique_word_distributions[category]['mean'])\n",
    "mean_unique_word_counts = dict(zip(categories, means))\n",
    "mean_unique_word_counts = dict(sorted(mean_unique_word_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "mean_unique_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song with the most unique words:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>category</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>unique_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>Momentum (feat. Black Thought &amp; Benny The Butc...</td>\n",
       "      <td>Russ</td>\n",
       "      <td>hiphop</td>\n",
       "      <td>Yeah yeah   Dont compare me to employees who ...</td>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   song artist category  \\\n",
       "1262  Momentum (feat. Black Thought & Benny The Butc...   Russ   hiphop   \n",
       "\n",
       "                                                 lyrics  unique_word_count  \n",
       "1262   Yeah yeah   Dont compare me to employees who ...                544  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres with songs that have the minimum unique word count of 25 words:\n",
      "['rock', 'country', 'punk', 'romance', 'classical', 'indie_alt', 'blues', 'metal'] \n",
      "\n",
      "25 songs have the minimum unique word count of 25 words.\n",
      "rock 5\n",
      "country 3\n",
      "punk 1\n",
      "romance 2\n",
      "classical 1\n",
      "indie_alt 8\n",
      "blues 2\n",
      "metal 3\n"
     ]
    }
   ],
   "source": [
    "# Find songs with the highest and lowest unique word counts\n",
    "print('Song with the most unique words:')\n",
    "display(nlp_df[nlp_df['unique_word_count']==max(nlp_df['unique_word_count'])][['song', 'artist', 'category', 'lyrics', 'unique_word_count']])\n",
    "\n",
    "print('Genres with songs that have the minimum unique word count of 25 words:')\n",
    "minimum_genres = list(nlp_df[nlp_df['unique_word_count']==min(nlp_df['unique_word_count'])]['category'])\n",
    "print(list(set(minimum_genres)), '\\n')\n",
    "\n",
    "min_word_count_df = nlp_df[nlp_df['unique_word_count']==min(nlp_df['unique_word_count'])]\n",
    "print(f'{len(min_word_count_df)} songs have the minimum unique word count of 25 words.')\n",
    "\n",
    "for genre in list(set(minimum_genres)):\n",
    "    print(genre, minimum_genres.count(genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blues</th>\n",
       "      <td>424.0</td>\n",
       "      <td>53.707547</td>\n",
       "      <td>19.685094</td>\n",
       "      <td>25.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>64.00</td>\n",
       "      <td>197.0</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classical</th>\n",
       "      <td>93.0</td>\n",
       "      <td>78.236559</td>\n",
       "      <td>64.720872</td>\n",
       "      <td>25.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>503.0</td>\n",
       "      <td>478.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>74.820207</td>\n",
       "      <td>24.007187</td>\n",
       "      <td>25.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>87.00</td>\n",
       "      <td>264.0</td>\n",
       "      <td>239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funk</th>\n",
       "      <td>282.0</td>\n",
       "      <td>73.092199</td>\n",
       "      <td>38.428545</td>\n",
       "      <td>26.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>83.75</td>\n",
       "      <td>257.0</td>\n",
       "      <td>231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hiphop</th>\n",
       "      <td>680.0</td>\n",
       "      <td>173.770588</td>\n",
       "      <td>74.667690</td>\n",
       "      <td>28.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>216.00</td>\n",
       "      <td>544.0</td>\n",
       "      <td>516.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indie_alt</th>\n",
       "      <td>660.0</td>\n",
       "      <td>57.984848</td>\n",
       "      <td>24.801422</td>\n",
       "      <td>25.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>68.00</td>\n",
       "      <td>253.0</td>\n",
       "      <td>228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jazz</th>\n",
       "      <td>198.0</td>\n",
       "      <td>60.656566</td>\n",
       "      <td>42.117834</td>\n",
       "      <td>26.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>65.00</td>\n",
       "      <td>349.0</td>\n",
       "      <td>323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metal</th>\n",
       "      <td>898.0</td>\n",
       "      <td>69.175947</td>\n",
       "      <td>26.775840</td>\n",
       "      <td>25.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>82.00</td>\n",
       "      <td>220.0</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop</th>\n",
       "      <td>693.0</td>\n",
       "      <td>69.748918</td>\n",
       "      <td>30.938040</td>\n",
       "      <td>26.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>78.00</td>\n",
       "      <td>360.0</td>\n",
       "      <td>334.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>punk</th>\n",
       "      <td>569.0</td>\n",
       "      <td>70.070299</td>\n",
       "      <td>30.317486</td>\n",
       "      <td>25.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>82.00</td>\n",
       "      <td>315.0</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnb</th>\n",
       "      <td>362.0</td>\n",
       "      <td>85.185083</td>\n",
       "      <td>33.778347</td>\n",
       "      <td>31.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>220.0</td>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rock</th>\n",
       "      <td>1225.0</td>\n",
       "      <td>63.481633</td>\n",
       "      <td>25.927782</td>\n",
       "      <td>25.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>74.00</td>\n",
       "      <td>308.0</td>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romance</th>\n",
       "      <td>279.0</td>\n",
       "      <td>59.559140</td>\n",
       "      <td>21.160127</td>\n",
       "      <td>25.0</td>\n",
       "      <td>45.5</td>\n",
       "      <td>57.0</td>\n",
       "      <td>71.00</td>\n",
       "      <td>166.0</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soul</th>\n",
       "      <td>411.0</td>\n",
       "      <td>70.644769</td>\n",
       "      <td>30.872600</td>\n",
       "      <td>26.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>82.00</td>\n",
       "      <td>238.0</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count        mean        std   min    25%    50%     75%    max  \\\n",
       "blues       424.0   53.707547  19.685094  25.0   39.0   51.0   64.00  197.0   \n",
       "classical    93.0   78.236559  64.720872  25.0   44.0   61.0   90.00  503.0   \n",
       "country    1257.0   74.820207  24.007187  25.0   60.0   73.0   87.00  264.0   \n",
       "funk        282.0   73.092199  38.428545  26.0   50.0   63.0   83.75  257.0   \n",
       "hiphop      680.0  173.770588  74.667690  28.0  123.0  166.0  216.00  544.0   \n",
       "indie_alt   660.0   57.984848  24.801422  25.0   41.0   54.0   68.00  253.0   \n",
       "jazz        198.0   60.656566  42.117834  26.0   39.0   51.0   65.00  349.0   \n",
       "metal       898.0   69.175947  26.775840  25.0   51.0   64.0   82.00  220.0   \n",
       "pop         693.0   69.748918  30.938040  26.0   53.0   64.0   78.00  360.0   \n",
       "punk        569.0   70.070299  30.317486  25.0   51.0   66.0   82.00  315.0   \n",
       "rnb         362.0   85.185083  33.778347  31.0   61.0   79.0  100.00  220.0   \n",
       "rock       1225.0   63.481633  25.927782  25.0   48.0   59.0   74.00  308.0   \n",
       "romance     279.0   59.559140  21.160127  25.0   45.5   57.0   71.00  166.0   \n",
       "soul        411.0   70.644769  30.872600  26.0   50.0   64.0   82.00  238.0   \n",
       "\n",
       "           range  \n",
       "blues      172.0  \n",
       "classical  478.0  \n",
       "country    239.0  \n",
       "funk       231.0  \n",
       "hiphop     516.0  \n",
       "indie_alt  228.0  \n",
       "jazz       323.0  \n",
       "metal      195.0  \n",
       "pop        334.0  \n",
       "punk       290.0  \n",
       "rnb        189.0  \n",
       "rock       283.0  \n",
       "romance    141.0  \n",
       "soul       212.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame of unique word count distributions\n",
    "ranges = []\n",
    "for category in unique_word_distributions:\n",
    "    ranges.append(unique_word_distributions[category]['max'] - unique_word_distributions[category]['min'])\n",
    "\n",
    "columns = ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'range']\n",
    "df_rows = []\n",
    "for index, category in enumerate(unique_word_distributions):\n",
    "    distribution = list(unique_word_distributions[category])\n",
    "    distribution.extend([ranges[index]])\n",
    "    df_rows.append(distribution)\n",
    "unique_word_count_df = pd.DataFrame(df_rows, index=list(unique_word_distributions.keys()), columns=columns)\n",
    "unique_word_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV\n",
    "unique_word_count_df.to_csv('../Data/Analysis/unique_word_count.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions about unique word distributions by genre\n",
    "- The hiphop genre has the highest mean unique word count of 174 words\n",
    "- The blues genre has the lowest mean unique word count of 54 words\n",
    "- Genres with the highest average unique word counts:\n",
    "    - Hiphop: 174 unique words\n",
    "    - R&B: 85 unique words\n",
    "    - Classical: 78 unique words\n",
    "- Genres with the lowest average unique word counts:\n",
    "    - Blues: 54 unique words\n",
    "    - Indie-alt: 58 unique words\n",
    "    - Jazz: 61 unique words\n",
    "- The song with the highest unique word count is in the romance category:\n",
    "    - Song name: Momentum \n",
    "    - Artist: Russ\n",
    "    - Unique word count: 544 words\n",
    "- The indie-alt genre had the most songs (8) with the minimum unique word count of 25 words\n",
    "    - The rock genre had the second most songs (5) with the minimum unique word count\n",
    "- The hiphop, R&B, funk, soul, pop, and jazz genres had the least songs (0) with the minimum unique word count of 25 words\n",
    "    - The classical and punk genres had the second least songs (1) with the minimum unique word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
