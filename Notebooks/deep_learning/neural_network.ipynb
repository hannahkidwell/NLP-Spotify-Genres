{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import time\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 55.38019800186157 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>category_id</th>\n",
       "      <th>genre_list</th>\n",
       "      <th>audio_ft_danceability</th>\n",
       "      <th>audio_ft_energy</th>\n",
       "      <th>audio_ft_key</th>\n",
       "      <th>audio_ft_mode</th>\n",
       "      <th>audio_ft_speechiness</th>\n",
       "      <th>...</th>\n",
       "      <th>entirely</th>\n",
       "      <th>basket</th>\n",
       "      <th>car</th>\n",
       "      <th>shawn</th>\n",
       "      <th>nothingness</th>\n",
       "      <th>amused</th>\n",
       "      <th>corners</th>\n",
       "      <th>interlude</th>\n",
       "      <th>sting</th>\n",
       "      <th>axis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>willow</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>pop</td>\n",
       "      <td>8.0</td>\n",
       "      <td>['dance', 'pop']</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.574</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stay Next To Me (with Chelsea Cutler)</td>\n",
       "      <td>Quinn XCII</td>\n",
       "      <td>pop</td>\n",
       "      <td>8.0</td>\n",
       "      <td>['indie', 'pop', 'electropop']</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.584</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WITHOUT YOU</td>\n",
       "      <td>The Kid LAROI</td>\n",
       "      <td>pop</td>\n",
       "      <td>8.0</td>\n",
       "      <td>['australian']</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 12025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               song_name    artist_name category_name  \\\n",
       "0                                 willow   Taylor Swift           pop   \n",
       "1  Stay Next To Me (with Chelsea Cutler)     Quinn XCII           pop   \n",
       "2                            WITHOUT YOU  The Kid LAROI           pop   \n",
       "\n",
       "   category_id                      genre_list  audio_ft_danceability  \\\n",
       "0          8.0                ['dance', 'pop']                  0.392   \n",
       "1          8.0  ['indie', 'pop', 'electropop']                  0.581   \n",
       "2          8.0                  ['australian']                  0.662   \n",
       "\n",
       "   audio_ft_energy  audio_ft_key  audio_ft_mode  audio_ft_speechiness  ...  \\\n",
       "0            0.574           7.0            1.0                0.1700  ...   \n",
       "1            0.584           2.0            1.0                0.2840  ...   \n",
       "2            0.413           0.0            1.0                0.0299  ...   \n",
       "\n",
       "   entirely  basket  car  shawn  nothingness  amused  corners  interlude  \\\n",
       "0       0.0     0.0  0.0    0.0          0.0     0.0      0.0        0.0   \n",
       "1       0.0     0.0  0.0    0.0          0.0     0.0      0.0        0.0   \n",
       "2       0.0     0.0  0.0    0.0          0.0     0.0      0.0        0.0   \n",
       "\n",
       "   sting  axis  \n",
       "0    0.0   0.0  \n",
       "1    0.0   0.0  \n",
       "2    0.0   0.0  \n",
       "\n",
       "[3 rows x 12025 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame from CSV\n",
    "t0 = time.time()\n",
    "filtered_lyric_TF_df = pd.read_csv('../../Data/filtered_lyric_TF.csv')\n",
    "filtered_lyric_TF_df = filtered_lyric_TF_df.drop([0,1])\n",
    "filtered_lyric_TF_df.index = filtered_lyric_TF_df.index - 2\n",
    "t1 = time.time()\n",
    "print(f'Run time: {t1-t0} seconds')\n",
    "filtered_lyric_TF_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_ft_danceability</th>\n",
       "      <th>audio_ft_energy</th>\n",
       "      <th>audio_ft_key</th>\n",
       "      <th>audio_ft_mode</th>\n",
       "      <th>audio_ft_speechiness</th>\n",
       "      <th>audio_ft_acousticness</th>\n",
       "      <th>audio_ft_instrumentalness</th>\n",
       "      <th>audio_ft_liveness</th>\n",
       "      <th>audio_ft_valence</th>\n",
       "      <th>audio_ft_tempo</th>\n",
       "      <th>...</th>\n",
       "      <th>entirely</th>\n",
       "      <th>basket</th>\n",
       "      <th>car</th>\n",
       "      <th>shawn</th>\n",
       "      <th>nothingness</th>\n",
       "      <th>amused</th>\n",
       "      <th>corners</th>\n",
       "      <th>interlude</th>\n",
       "      <th>sting</th>\n",
       "      <th>axis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.392</td>\n",
       "      <td>0.574</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.8330</td>\n",
       "      <td>0.00179</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.529</td>\n",
       "      <td>81.112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.581</td>\n",
       "      <td>0.584</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2840</td>\n",
       "      <td>0.0805</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.756</td>\n",
       "      <td>179.954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.662</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.2130</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.467</td>\n",
       "      <td>93.005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 12020 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   audio_ft_danceability  audio_ft_energy  audio_ft_key  audio_ft_mode  \\\n",
       "0                  0.392            0.574           7.0            1.0   \n",
       "1                  0.581            0.584           2.0            1.0   \n",
       "2                  0.662            0.413           0.0            1.0   \n",
       "\n",
       "   audio_ft_speechiness  audio_ft_acousticness  audio_ft_instrumentalness  \\\n",
       "0                0.1700                 0.8330                    0.00179   \n",
       "1                0.2840                 0.0805                    0.00000   \n",
       "2                0.0299                 0.2130                    0.00000   \n",
       "\n",
       "   audio_ft_liveness  audio_ft_valence  audio_ft_tempo  ...  entirely  basket  \\\n",
       "0              0.145             0.529          81.112  ...       0.0     0.0   \n",
       "1              0.366             0.756         179.954  ...       0.0     0.0   \n",
       "2              0.134             0.467          93.005  ...       0.0     0.0   \n",
       "\n",
       "   car  shawn  nothingness  amused  corners  interlude  sting  axis  \n",
       "0  0.0    0.0          0.0     0.0      0.0        0.0    0.0   0.0  \n",
       "1  0.0    0.0          0.0     0.0      0.0        0.0    0.0   0.0  \n",
       "2  0.0    0.0          0.0     0.0      0.0        0.0    0.0   0.0  \n",
       "\n",
       "[3 rows x 12020 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the features set\n",
    "X = filtered_lyric_TF_df.copy()\n",
    "X = X.drop(['song_name', 'artist_name', 'category_name', 'category_id', 'genre_list'], axis=1)\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8., 8., 8., 8., 8.])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the target set\n",
    "y = filtered_lyric_TF_df['category_id'].ravel()\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6010, 12020)\n",
      "(2004, 12020)\n",
      "(6010,)\n",
      "(2004,)\n"
     ]
    }
   ],
   "source": [
    "# Split into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the Standard Scaler with the training data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Keras Sequential model\n",
    "nn_model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first Dense layer, including the input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation='relu', input_dim=len(X.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the output layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 1)                 12021     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 12,023\n",
      "Trainable params: 12,023\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of the Sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -23.2608 - accuracy: 0.0103\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -130.4368 - accuracy: 0.0103\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -321.8388 - accuracy: 0.0103\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -595.4487 - accuracy: 0.0103\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -948.4146 - accuracy: 0.0103\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -1375.3978 - accuracy: 0.0103\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -1871.2058 - accuracy: 0.0103\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -2433.1062 - accuracy: 0.0103\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: -3057.9910 - accuracy: 0.0103\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: -3742.2546 - accuracy: 0.0103\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -4483.3779 - accuracy: 0.0103\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -5278.7256 - accuracy: 0.0103\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -6125.3164 - accuracy: 0.0103\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -7022.4126 - accuracy: 0.0103\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -7968.7056 - accuracy: 0.0103\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -8960.7822 - accuracy: 0.0103\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -9998.9521 - accuracy: 0.0103\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -11082.0146 - accuracy: 0.0103\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -12208.8408 - accuracy: 0.0103\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -13380.0547 - accuracy: 0.0103\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -14594.1416 - accuracy: 0.0103\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -15850.2266 - accuracy: 0.0103\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -17146.1133 - accuracy: 0.0103\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -18482.5449 - accuracy: 0.0103\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -19859.8516 - accuracy: 0.0103\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -21276.6250 - accuracy: 0.0103\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -22734.8281 - accuracy: 0.0103\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -24229.9336 - accuracy: 0.0103\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -25763.5625 - accuracy: 0.0103\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -27337.5332 - accuracy: 0.0103\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -28952.6836 - accuracy: 0.0103\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -30605.4023 - accuracy: 0.0103\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -32295.2578 - accuracy: 0.0103\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -34021.6328 - accuracy: 0.0103\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -35788.1484 - accuracy: 0.0103\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -37593.0898 - accuracy: 0.0103\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -39435.7773 - accuracy: 0.0103\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -41315.4102 - accuracy: 0.0103\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -43232.1445 - accuracy: 0.0103\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -45186.5703 - accuracy: 0.0103\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -47179.1797 - accuracy: 0.0103\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -49208.3906 - accuracy: 0.0103\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -51274.0508 - accuracy: 0.0103\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -53377.2578 - accuracy: 0.0103\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -55517.9922 - accuracy: 0.0103\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -57695.0352 - accuracy: 0.0103\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -59910.6094 - accuracy: 0.0103\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -62163.2422 - accuracy: 0.0103\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -64451.8242 - accuracy: 0.0103\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -66777.6719 - accuracy: 0.0103\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -69140.8203 - accuracy: 0.0103\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -71541.2891 - accuracy: 0.0103\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -73979.3125 - accuracy: 0.0103\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -76453.8750 - accuracy: 0.0103\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -78962.9609 - accuracy: 0.0103\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: -81508.3438 - accuracy: 0.0103\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -84090.7266 - accuracy: 0.0103\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -86710.1406 - accuracy: 0.0103\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -89366.0859 - accuracy: 0.0103\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -92059.0234 - accuracy: 0.0103A: 0s - loss: -92046.9375 - accuracy: 0.01\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -94790.2734 - accuracy: 0.0103\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -97556.8281 - accuracy: 0.0103\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -100359.6484 - accuracy: 0.0103\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -103201.5000 - accuracy: 0.0103\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: -106078.1016 - accuracy: 0.0103\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -108990.8047 - accuracy: 0.0103\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -111938.6094 - accuracy: 0.0103\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -114922.1484 - accuracy: 0.0103\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -117941.9609 - accuracy: 0.0103\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -120999.3672 - accuracy: 0.0103\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -124092.5312 - accuracy: 0.0103\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: -127222.2109 - accuracy: 0.0103\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: -130389.0000 - accuracy: 0.0103\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -133593.1719 - accuracy: 0.0103\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -136833.6562 - accuracy: 0.0103\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -140105.4375 - accuracy: 0.0103\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 2ms/step - loss: -143409.0312 - accuracy: 0.0103: 0s - loss: -145488.3906 - accuracy: \n",
      "Epoch 78/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -146751.8438 - accuracy: 0.0103\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -150128.7500 - accuracy: 0.0103\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -153544.5625 - accuracy: 0.0103\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -157000.2969 - accuracy: 0.0103\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -160492.5469 - accuracy: 0.0103\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -164019.3125 - accuracy: 0.0103\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -167580.5781 - accuracy: 0.0103\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -171176.1094 - accuracy: 0.0103\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -174806.7656 - accuracy: 0.0103\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -178475.7500 - accuracy: 0.0103\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -182182.1406 - accuracy: 0.0103\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -185923.0000 - accuracy: 0.0103\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -189698.5938 - accuracy: 0.0103\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -193512.5469 - accuracy: 0.0103\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -197360.0625 - accuracy: 0.0103\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -201243.1562 - accuracy: 0.0103\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -205159.3438 - accuracy: 0.0103\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -209117.3906 - accuracy: 0.0103\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -213110.2031 - accuracy: 0.0103\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -217137.4688 - accuracy: 0.0103\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -221204.4062 - accuracy: 0.0103\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -225306.9844 - accuracy: 0.0103\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -229444.2656 - accuracy: 0.0103\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing history\n",
    "history_df = pd.DataFrame(fit_model.history, index=range(1, len(fit_model.history['loss'])+1))\n",
    "\n",
    "# Plot the loss\n",
    "history_df.plot(y='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy\n",
    "history_df.plot(y='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 - 0s - loss: -1.6907e+05 - accuracy: 0.0105\n",
      "Loss: -169065.046875, Accuracy: 0.010479042306542397\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f'Loss: {model_loss}, Accuracy: {model_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -258.8247 - accuracy: 0.0101\n",
      "Epoch 2/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -6946.2148 - accuracy: 0.0103: 0s - loss: -6642.0513 - accuracy: 0.01\n",
      "Epoch 3/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -40283.0391 - accuracy: 0.0103\n",
      "Epoch 4/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -123222.0312 - accuracy: 0.0103\n",
      "Epoch 5/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -275091.9375 - accuracy: 0.0103\n",
      "Epoch 6/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -521349.8750 - accuracy: 0.0103\n",
      "Epoch 7/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -871439.9375 - accuracy: 0.0103\n",
      "Epoch 8/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -1334036.7500 - accuracy: 0.0103\n",
      "Epoch 9/50\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -1917001.6250 - accuracy: 0.0103\n",
      "Epoch 10/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -2626220.5000 - accuracy: 0.0103\n",
      "Epoch 11/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -3467980.2500 - accuracy: 0.0103\n",
      "Epoch 12/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -4446422.5000 - accuracy: 0.0103\n",
      "Epoch 13/50\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -5564106.5000 - accuracy: 0.0103\n",
      "Epoch 14/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -6828245.5000 - accuracy: 0.0103\n",
      "Epoch 15/50\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -8243181.5000 - accuracy: 0.0103\n",
      "Epoch 16/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -9808902.0000 - accuracy: 0.0103\n",
      "Epoch 17/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: -11530622.0000 - accuracy: 0.0103: 0s - loss: -11287135.0000 - \n",
      "Epoch 18/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -13410443.0000 - accuracy: 0.0103\n",
      "Epoch 19/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -15451151.0000 - accuracy: 0.0103\n",
      "Epoch 20/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -17655290.0000 - accuracy: 0.0103\n",
      "Epoch 21/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -20028004.0000 - accuracy: 0.0103\n",
      "Epoch 22/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -22569946.0000 - accuracy: 0.0103\n",
      "Epoch 23/50\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -25283104.0000 - accuracy: 0.0103\n",
      "Epoch 24/50\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -28176576.0000 - accuracy: 0.0103\n",
      "Epoch 25/50\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -31249782.0000 - accuracy: 0.0103\n",
      "Epoch 26/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -34502644.0000 - accuracy: 0.0103\n",
      "Epoch 27/50\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -37940700.0000 - accuracy: 0.0103\n",
      "Epoch 28/50\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -41568432.0000 - accuracy: 0.0103\n",
      "Epoch 29/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -45389684.0000 - accuracy: 0.0103\n",
      "Epoch 30/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -49404564.0000 - accuracy: 0.0103\n",
      "Epoch 31/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -53619564.0000 - accuracy: 0.0103\n",
      "Epoch 32/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -58036172.0000 - accuracy: 0.0103\n",
      "Epoch 33/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -62661136.0000 - accuracy: 0.0103\n",
      "Epoch 34/50\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -67494816.0000 - accuracy: 0.0103\n",
      "Epoch 35/50\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -72541136.0000 - accuracy: 0.0103\n",
      "Epoch 36/50\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -77796824.0000 - accuracy: 0.0103\n",
      "Epoch 37/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: -83265800.0000 - accuracy: 0.0103\n",
      "Epoch 38/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -88956640.0000 - accuracy: 0.0103\n",
      "Epoch 39/50\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -94881040.0000 - accuracy: 0.0103\n",
      "Epoch 40/50\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -101033256.0000 - accuracy: 0.0103\n",
      "Epoch 41/50\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -107425888.0000 - accuracy: 0.0103\n",
      "Epoch 42/50\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -114050064.0000 - accuracy: 0.0103\n",
      "Epoch 43/50\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -120915096.0000 - accuracy: 0.0103\n",
      "Epoch 44/50\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -128017640.0000 - accuracy: 0.0103\n",
      "Epoch 45/50\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -135367504.0000 - accuracy: 0.0103\n",
      "Epoch 46/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -142968112.0000 - accuracy: 0.0103\n",
      "Epoch 47/50\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -150821408.0000 - accuracy: 0.0103\n",
      "Epoch 48/50\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -158925216.0000 - accuracy: 0.0103\n",
      "Epoch 49/50\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -167288496.0000 - accuracy: 0.0103\n",
      "Epoch 50/50\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -175922336.0000 - accuracy: 0.0103\n",
      "63/63 - 0s - loss: -1.3242e+08 - accuracy: 0.0105\n",
      "Loss: -132416176.0, Accuracy: 0.010479042306542397\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 =  24\n",
    "hidden_nodes_layer2 = 12\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(\n",
    "    units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 - 0s - loss: -3.4605e+10 - accuracy: 0.0105\n",
      "Loss: -34605125632.0, Accuracy: 0.010479042306542397\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple-Neuron Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our new Sequential model\n",
    "new_model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the input and hidden layer\n",
    "number_inputs = len(X_train_scaled[0])\n",
    "number_hidden_nodes = 6\n",
    "\n",
    "new_model.add(tf.keras.layers.Dense(units=number_hidden_nodes, activation=\"relu\", input_dim=number_inputs))\n",
    "\n",
    "# Add the output layer that uses a probability activation function\n",
    "new_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -62.5640 - accuracy: 0.0136\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -391.0019 - accuracy: 0.0136\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -856.5234 - accuracy: 0.0133\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -1478.4001 - accuracy: 0.0130A: 0s - loss: -1273.9006 - \n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -2263.1702 - accuracy: 0.0141\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -3217.3105 - accuracy: 0.0133\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -4340.5752 - accuracy: 0.0111\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -5626.9717 - accuracy: 0.0103\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 1s 7ms/step - loss: -7070.5317 - accuracy: 0.0103\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 1s 7ms/step - loss: -8666.6426 - accuracy: 0.0103\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 1s 5ms/step - loss: -10419.3740 - accuracy: 0.0103A: 0s - loss: -10263.8555 - accuracy: 0\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -12328.6719 - accuracy: 0.0103\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -14399.0391 - accuracy: 0.0103\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -16634.7363 - accuracy: 0.0103\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -19053.1348 - accuracy: 0.0103\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -21646.2168 - accuracy: 0.0103\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -24414.6719 - accuracy: 0.0103\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -27361.7285 - accuracy: 0.0103\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -30480.2129 - accuracy: 0.0103\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -33762.7539 - accuracy: 0.0103\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -37207.1836 - accuracy: 0.0103\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -40813.3594 - accuracy: 0.0103\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -44585.3477 - accuracy: 0.0103\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -48520.5078 - accuracy: 0.0103\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -52605.5195 - accuracy: 0.0103\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -56829.8008 - accuracy: 0.0103\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -61208.3906 - accuracy: 0.0103\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -65731.9766 - accuracy: 0.0103\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -70399.5156 - accuracy: 0.0103\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -75213.2734 - accuracy: 0.0103\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -80179.1719 - accuracy: 0.0103\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -85287.9141 - accuracy: 0.0103\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -90543.4297 - accuracy: 0.0103A: 0s - loss: -90712.5234 - accuracy: 0.010\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -95954.8359 - accuracy: 0.0103\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -101512.0000 - accuracy: 0.0103\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -107219.3516 - accuracy: 0.0103\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -113072.9531 - accuracy: 0.0103\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -119070.9453 - accuracy: 0.0103\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -125234.0312 - accuracy: 0.0103\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: -131540.1719 - accuracy: 0.0103\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -137994.7969 - accuracy: 0.0103\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -144605.0469 - accuracy: 0.0103\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -151369.4219 - accuracy: 0.0103\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -158282.1406 - accuracy: 0.0103\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -165348.8281 - accuracy: 0.0103\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -172572.5781 - accuracy: 0.0103\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -179944.0469 - accuracy: 0.0103\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -187462.4688 - accuracy: 0.0103\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -195134.2188 - accuracy: 0.0103\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -202963.3594 - accuracy: 0.0103\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -210953.2656 - accuracy: 0.0103\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -219091.4219 - accuracy: 0.0103\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -227391.2344 - accuracy: 0.0103\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -235827.5156 - accuracy: 0.0103\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -244419.0312 - accuracy: 0.0103\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -253171.3281 - accuracy: 0.0103\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -262074.8438 - accuracy: 0.0103\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -271144.3750 - accuracy: 0.0103\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -280376.6562 - accuracy: 0.0103\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -289753.8438 - accuracy: 0.0103\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -299302.4062 - accuracy: 0.0103\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -309001.3125 - accuracy: 0.0103\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -318861.0625 - accuracy: 0.0103\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -328881.5625 - accuracy: 0.0103\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -339065.6250 - accuracy: 0.0103\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -349405.8438 - accuracy: 0.0103\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -359916.7500 - accuracy: 0.0103\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -370588.0625 - accuracy: 0.0103\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -381431.0625 - accuracy: 0.0103\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -392428.9062 - accuracy: 0.0103\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -403579.2812 - accuracy: 0.0103\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -414888.9688 - accuracy: 0.0103\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -426362.7500 - accuracy: 0.0103\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -437994.2812 - accuracy: 0.0103\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -449807.5625 - accuracy: 0.0103\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 1s 3ms/step - loss: -461791.8750 - accuracy: 0.0103\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -473932.7188 - accuracy: 0.0103\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -486241.8438 - accuracy: 0.0103\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -498714.6562 - accuracy: 0.0103\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -511349.7500 - accuracy: 0.0103\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -524154.8125 - accuracy: 0.0103\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -537130.6250 - accuracy: 0.0103\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -550276.2500 - accuracy: 0.0103\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -563583.3125 - accuracy: 0.0103\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -577059.7500 - accuracy: 0.0103\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -590709.7500 - accuracy: 0.0103\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -604539.4375 - accuracy: 0.0103\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -618542.7500 - accuracy: 0.0103\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -632721.3125 - accuracy: 0.0103\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -647062.6250 - accuracy: 0.0103\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -661565.4375 - accuracy: 0.0103\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -676244.6875 - accuracy: 0.0103\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -691077.5625 - accuracy: 0.0103\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -706083.9375 - accuracy: 0.0103\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -721254.7500 - accuracy: 0.0103\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: -736586.3125 - accuracy: 0.0103\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -752077.9375 - accuracy: 0.0103\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -767739.0625 - accuracy: 0.0103\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: -783565.5625 - accuracy: 0.0103\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: -799575.0000 - accuracy: 0.0103\n"
     ]
    }
   ],
   "source": [
    "# Compile the Sequential model together and customize metrics\n",
    "new_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model to the training data\n",
    "new_fit_model = new_model.fit(X_train_scaled, y_train, epochs=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Data adapters should be mutually exclusive for handling inputs. Found multiple adapters [<class 'tensorflow.python.keras.engine.data_adapter.TensorLikeDataAdapter'>, <class 'tensorflow.python.keras.engine.data_adapter.GeneratorDataAdapter'>] to handle input: <class 'pandas.core.frame.DataFrame'>, <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-955023d5f64c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate the model using the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loss: {model_loss}, Accuracy: {model_accuracy}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1354\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m             steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0;34m\"handling inputs. Found multiple adapters {} to handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 977\u001b[0;31m             adapter_cls, _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    978\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Data adapters should be mutually exclusive for handling inputs. Found multiple adapters [<class 'tensorflow.python.keras.engine.data_adapter.TensorLikeDataAdapter'>, <class 'tensorflow.python.keras.engine.data_adapter.GeneratorDataAdapter'>] to handle input: <class 'pandas.core.frame.DataFrame'>, <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = new_model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synaptic Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skill Drill:\n",
    "Try plotting a variable using Pandas' Series.plot method to look for outliers that can help identify if a particular numerical variable is causing confusion in a model. <br>\n",
    "Try leaving out a noisy variable from the rest of the training features and see if the model performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
