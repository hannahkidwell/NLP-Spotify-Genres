{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 40.63580918312073 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>category_id</th>\n",
       "      <th>genre_list</th>\n",
       "      <th>audio_ft_danceability</th>\n",
       "      <th>audio_ft_energy</th>\n",
       "      <th>audio_ft_key</th>\n",
       "      <th>audio_ft_mode</th>\n",
       "      <th>audio_ft_speechiness</th>\n",
       "      <th>...</th>\n",
       "      <th>entirely</th>\n",
       "      <th>basket</th>\n",
       "      <th>car</th>\n",
       "      <th>shawn</th>\n",
       "      <th>nothingness</th>\n",
       "      <th>amused</th>\n",
       "      <th>corners</th>\n",
       "      <th>interlude</th>\n",
       "      <th>sting</th>\n",
       "      <th>axis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-2</th>\n",
       "      <td>8015</td>\n",
       "      <td>8015</td>\n",
       "      <td>8015</td>\n",
       "      <td>7592.0</td>\n",
       "      <td>8015</td>\n",
       "      <td>8015.0000</td>\n",
       "      <td>8015.0000</td>\n",
       "      <td>7150.0</td>\n",
       "      <td>5501.0</td>\n",
       "      <td>8015.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53368.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4518.1163</td>\n",
       "      <td>5348.9565</td>\n",
       "      <td>42484.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>664.1198</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>willow</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>pop</td>\n",
       "      <td>8.0</td>\n",
       "      <td>['dance', 'pop']</td>\n",
       "      <td>0.3920</td>\n",
       "      <td>0.5740</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stay Next To Me (with Chelsea Cutler)</td>\n",
       "      <td>Quinn XCII</td>\n",
       "      <td>pop</td>\n",
       "      <td>8.0</td>\n",
       "      <td>['indie', 'pop', 'electropop']</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>0.5840</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WITHOUT YOU</td>\n",
       "      <td>The Kid LAROI</td>\n",
       "      <td>pop</td>\n",
       "      <td>8.0</td>\n",
       "      <td>['australian']</td>\n",
       "      <td>0.6620</td>\n",
       "      <td>0.4130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 12025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                song_name    artist_name category_name  \\\n",
       "-2                                   8015           8015          8015   \n",
       "-1                                    NaN            NaN           NaN   \n",
       "0                                  willow   Taylor Swift           pop   \n",
       "1   Stay Next To Me (with Chelsea Cutler)     Quinn XCII           pop   \n",
       "2                             WITHOUT YOU  The Kid LAROI           pop   \n",
       "\n",
       "    category_id                      genre_list  audio_ft_danceability  \\\n",
       "-2       7592.0                            8015              8015.0000   \n",
       "-1      53368.0                             NaN              4518.1163   \n",
       "0           8.0                ['dance', 'pop']                 0.3920   \n",
       "1           8.0  ['indie', 'pop', 'electropop']                 0.5810   \n",
       "2           8.0                  ['australian']                 0.6620   \n",
       "\n",
       "    audio_ft_energy  audio_ft_key  audio_ft_mode  audio_ft_speechiness  ...  \\\n",
       "-2        8015.0000        7150.0         5501.0             8015.0000  ...   \n",
       "-1        5348.9565       42484.0         5500.0              664.1198  ...   \n",
       "0            0.5740           7.0            1.0                0.1700  ...   \n",
       "1            0.5840           2.0            1.0                0.2840  ...   \n",
       "2            0.4130           0.0            1.0                0.0299  ...   \n",
       "\n",
       "    entirely  basket    car  shawn  nothingness  amused  corners  interlude  \\\n",
       "-2       5.0    11.0  385.0    7.0          9.0     6.0     24.0        8.0   \n",
       "-1       5.0    14.0  681.0    7.0         10.0     7.0     31.0        7.0   \n",
       "0        0.0     0.0    0.0    0.0          0.0     0.0      0.0        0.0   \n",
       "1        0.0     0.0    0.0    0.0          0.0     0.0      0.0        0.0   \n",
       "2        0.0     0.0    0.0    0.0          0.0     0.0      0.0        0.0   \n",
       "\n",
       "    sting  axis  \n",
       "-2   34.0   5.0  \n",
       "-1   49.0   4.0  \n",
       "0     0.0   0.0  \n",
       "1     0.0   0.0  \n",
       "2     0.0   0.0  \n",
       "\n",
       "[5 rows x 12025 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame from CSV\n",
    "t0 = time.time()\n",
    "filtered_lyric_TF_df = pd.read_csv('../../Data/filtered_lyric_TF.csv')\n",
    "#filtered_lyric_TF_df = filtered_lyric_TF_df.drop([0,1])\n",
    "filtered_lyric_TF_df.index = filtered_lyric_TF_df.index - 2\n",
    "t1 = time.time()\n",
    "print(f'Run time: {t1-t0} seconds')\n",
    "filtered_lyric_TF_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blues 0.0\n",
      "classical 1.0\n",
      "country 2.0\n",
      "funk 3.0\n",
      "hiphop 4.0\n",
      "indie_alt 5.0\n",
      "jazz 6.0\n",
      "metal 7.0\n",
      "pop 8.0\n",
      "punk 9.0\n",
      "rnb 10.0\n",
      "rock 11.0\n",
      "romance 12.0\n",
      "soul 13.0\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary of category names and ids\n",
    "cat_name_id = {}\n",
    "category_list = ['blues', 'classical', 'country', 'funk', 'hiphop', 'indie_alt', 'jazz', \n",
    "                 'metal', 'pop', 'punk', 'rnb', 'rock', 'romance', 'soul']\n",
    "for cat in category_list:\n",
    "    cat_id = list(filtered_lyric_TF_df[filtered_lyric_TF_df['category_name']==cat]['category_id'])[0]\n",
    "    cat_name_id[cat] = cat_id\n",
    "    print(cat, cat_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame and combine the columns for the singular and plural n-word\n",
    "new_lyric_TF_df = filtered_lyric_TF_df.drop([-2, -1])\n",
    "for i in range(len(new_lyric_TF_df)):\n",
    "    new_lyric_TF_df.at[i, 'nigga'] = new_lyric_TF_df.at[i, 'nigga'] + new_lyric_TF_df.at[i, 'niggas']\n",
    "new_lyric_TF_df = new_lyric_TF_df.drop('niggas', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'im': 25280.0,\n",
       " 'dont': 17907.0,\n",
       " '?': 16604.0,\n",
       " 'like': 16012.0,\n",
       " 'know': 15030.0,\n",
       " 'oh': 14976.0,\n",
       " 'yeah': 14800.0,\n",
       " 'love': 14119.0,\n",
       " 'got': 11280.0,\n",
       " 'get': 10844.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of the overall top ten words \n",
    "word_count_df = filtered_lyric_TF_df[1:2][filtered_lyric_TF_df.columns[17:]]\n",
    "word_count_df = word_count_df.sort_values(by=[-1], axis=1, ascending=False)\n",
    "top_word_counts = list(word_count_df.loc[-1])[0:10]\n",
    "top_ten = dict(zip(list(word_count_df)[0:10], top_word_counts))\n",
    "top_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 5.531065940856934 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary of the top ten words for each category\n",
    "t0 = time.time()\n",
    "top_words = {}\n",
    "df_rows = []\n",
    "blues_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='blues'].copy()\n",
    "blues_df.loc[0] = blues_df.sum(numeric_only=True)\n",
    "blues_words = blues_df.sort_index()[blues_df.columns[17:]][0:1]\n",
    "blues_words = blues_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(blues_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(blues_words)[0:10], top_word_counts))\n",
    "top_words['blues'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "classical_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='classical'].copy()\n",
    "classical_df.loc[0] = classical_df.sum(numeric_only=True)\n",
    "classical_words = classical_df.sort_index()[classical_df.columns[17:]][0:1]\n",
    "classical_words = classical_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(classical_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(classical_words), top_word_counts))\n",
    "top_words['classical'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "country_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='country'].copy()\n",
    "country_df.loc[0] = country_df.sum(numeric_only=True)\n",
    "country_words = country_df.sort_index()[country_df.columns[17:]][0:1]\n",
    "country_words = country_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(country_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(country_words)[0:10], top_word_counts))\n",
    "top_words['country'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "funk_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='funk'].copy()\n",
    "funk_df.loc[0] = funk_df.sum(numeric_only=True)\n",
    "funk_words = funk_df.sort_index()[funk_df.columns[17:]][0:1]\n",
    "funk_words = funk_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(funk_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(funk_words)[0:10], top_word_counts))\n",
    "top_words['funk'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "hiphop_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='hiphop'].copy()\n",
    "hiphop_df.loc[0] = hiphop_df.sum(numeric_only=True)\n",
    "hiphop_words = hiphop_df.sort_index()[hiphop_df.columns[17:]][0:1]\n",
    "hiphop_words = hiphop_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(hiphop_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(hiphop_words)[0:10], top_word_counts))\n",
    "top_words['hiphop'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "indie_alt_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='indie_alt'].copy()\n",
    "indie_alt_df.loc[0] = indie_alt_df.sum(numeric_only=True)\n",
    "indie_alt_words = indie_alt_df.sort_index()[indie_alt_df.columns[17:]][0:1]\n",
    "indie_alt_words = indie_alt_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(indie_alt_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(indie_alt_words)[0:10], top_word_counts))\n",
    "top_words['indie_alt'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "jazz_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='jazz'].copy()\n",
    "jazz_df.loc[0] = jazz_df.sum(numeric_only=True)\n",
    "jazz_words = jazz_df.sort_index()[jazz_df.columns[17:]][0:1]\n",
    "jazz_words = jazz_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(jazz_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(jazz_words)[0:10], top_word_counts))\n",
    "top_words['jazz'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "metal_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='metal'].copy()\n",
    "metal_df.loc[0] = metal_df.sum(numeric_only=True)\n",
    "metal_words = metal_df.sort_index()[metal_df.columns[17:]][0:1]\n",
    "metal_words = metal_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(metal_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(metal_words)[0:10], top_word_counts))\n",
    "top_words['metal'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "pop_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='pop'].copy()\n",
    "pop_df.loc[-1] = pop_df.sum(numeric_only=True)\n",
    "pop_words = pop_df.sort_index()[pop_df.columns[17:]]\n",
    "pop_words = pop_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(pop_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(pop_words)[0:10], top_word_counts))\n",
    "top_words['pop'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "punk_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='punk'].copy()\n",
    "punk_df.loc[0] = punk_df.sum(numeric_only=True)\n",
    "punk_words = punk_df.sort_index()[punk_df.columns[17:]][0:1]\n",
    "punk_words = punk_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(punk_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(punk_words)[0:10], top_word_counts))\n",
    "top_words['punk'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "rnb_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='rnb'].copy()\n",
    "rnb_df.loc[0] = rnb_df.sum(numeric_only=True)\n",
    "rnb_words = rnb_df.sort_index()[rnb_df.columns[17:]][0:1]\n",
    "rnb_words = rnb_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(rnb_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(rnb_words)[0:10], top_word_counts))\n",
    "top_words['rnb'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "rock_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='rock'].copy()\n",
    "rock_df.loc[0] = rock_df.sum(numeric_only=True)\n",
    "rock_words = rock_df.sort_index()[rock_df.columns[17:]][0:1]\n",
    "rock_words = rock_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(rock_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(rock_words)[0:10], top_word_counts))\n",
    "top_words['rock'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "romance_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='romance'].copy()\n",
    "romance_df.loc[0] = romance_df.sum(numeric_only=True)\n",
    "romance_words = romance_df.sort_index()[romance_df.columns[17:]][0:1]\n",
    "romance_words = romance_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(romance_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(romance_words)[0:10], top_word_counts))\n",
    "top_words['romance'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "soul_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='soul'].copy()\n",
    "soul_df.loc[0] = soul_df.sum(numeric_only=True)\n",
    "soul_words = soul_df.sort_index()[soul_df.columns[17:]][0:1]\n",
    "soul_words = soul_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(soul_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(soul_words)[0:10], top_word_counts))\n",
    "top_words['soul'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "t1 = time.time()\n",
    "print(f'Run time: {t1-t0} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blues': {'im': 968.0,\n",
       "  'baby': 809.0,\n",
       "  'dont': 768.0,\n",
       "  'love': 644.0,\n",
       "  'know': 640.0,\n",
       "  'got': 640.0,\n",
       "  'oh': 486.0,\n",
       "  '?': 455.0,\n",
       "  'well': 374.0,\n",
       "  'man': 350.0},\n",
       " 'classical': {'im': 126.0,\n",
       "  'one': 109.0,\n",
       "  'come': 105.0,\n",
       "  'love': 96.0,\n",
       "  '!': 89.0,\n",
       "  'dont': 87.0,\n",
       "  'get': 86.0,\n",
       "  '?': 74.0,\n",
       "  'know': 73.0,\n",
       "  'like': 71.0},\n",
       " 'country': {'im': 3013.0,\n",
       "  'like': 2460.0,\n",
       "  'dont': 2382.0,\n",
       "  'love': 2025.0,\n",
       "  'got': 1959.0,\n",
       "  'yeah': 1935.0,\n",
       "  'know': 1908.0,\n",
       "  'oh': 1887.0,\n",
       "  'aint': 1712.0,\n",
       "  '?': 1645.0},\n",
       " 'funk': {'get': 986.0,\n",
       "  '!': 820.0,\n",
       "  'baby': 814.0,\n",
       "  'love': 783.0,\n",
       "  'dont': 772.0,\n",
       "  'oh': 746.0,\n",
       "  'im': 680.0,\n",
       "  'yeah': 679.0,\n",
       "  'got': 638.0,\n",
       "  '?': 632.0},\n",
       " 'hiphop': {'im': 5176.0,\n",
       "  'like': 3895.0,\n",
       "  'yeah': 3749.0,\n",
       "  'nigga': 3248.0,\n",
       "  'got': 2823.0,\n",
       "  'dont': 2722.0,\n",
       "  '?': 2676.0,\n",
       "  'get': 2399.0,\n",
       "  'know': 2317.0,\n",
       "  'aint': 2036.0},\n",
       " 'indie_alt': {'im': 1555.0,\n",
       "  'oh': 1294.0,\n",
       "  '?': 1288.0,\n",
       "  'dont': 1177.0,\n",
       "  'know': 1026.0,\n",
       "  'like': 905.0,\n",
       "  'love': 776.0,\n",
       "  'youre': 736.0,\n",
       "  'time': 682.0,\n",
       "  'ooh': 623.0},\n",
       " 'jazz': {'love': 490.0,\n",
       "  'im': 351.0,\n",
       "  'dont': 284.0,\n",
       "  'know': 231.0,\n",
       "  '?': 223.0,\n",
       "  'baby': 220.0,\n",
       "  'like': 206.0,\n",
       "  'let': 184.0,\n",
       "  'come': 182.0,\n",
       "  'time': 181.0},\n",
       " 'metal': {'im': 1644.0,\n",
       "  '?': 1464.0,\n",
       "  '!': 1462.0,\n",
       "  'cant': 887.0,\n",
       "  'dont': 874.0,\n",
       "  'see': 791.0,\n",
       "  'never': 774.0,\n",
       "  'one': 760.0,\n",
       "  'like': 745.0,\n",
       "  'know': 710.0},\n",
       " 'pop': {'thats': 13.0,\n",
       "  'man': 13.0,\n",
       "  'take': 11.0,\n",
       "  'im': 10.0,\n",
       "  'wreck': 8.0,\n",
       "  'plans': 8.0,\n",
       "  'hand': 8.0,\n",
       "  'begging': 8.0,\n",
       "  'know': 7.0,\n",
       "  'like': 7.0},\n",
       " 'punk': {'im': 1619.0,\n",
       "  '?': 1181.0,\n",
       "  'dont': 1025.0,\n",
       "  'know': 843.0,\n",
       "  'like': 779.0,\n",
       "  'oh': 764.0,\n",
       "  'youre': 669.0,\n",
       "  '!': 590.0,\n",
       "  'go': 575.0,\n",
       "  'never': 574.0},\n",
       " 'rnb': {'love': 1871.0,\n",
       "  'oh': 1817.0,\n",
       "  'yeah': 1779.0,\n",
       "  'im': 1612.0,\n",
       "  'baby': 1407.0,\n",
       "  'dont': 1394.0,\n",
       "  'know': 1374.0,\n",
       "  'like': 1166.0,\n",
       "  '?': 1104.0,\n",
       "  'youre': 794.0},\n",
       " 'rock': {'im': 3547.0,\n",
       "  '?': 2629.0,\n",
       "  'dont': 2580.0,\n",
       "  'oh': 2502.0,\n",
       "  'like': 1964.0,\n",
       "  'know': 1889.0,\n",
       "  'yeah': 1689.0,\n",
       "  'time': 1480.0,\n",
       "  'love': 1472.0,\n",
       "  'go': 1416.0},\n",
       " 'romance': {'love': 1135.0,\n",
       "  'im': 618.0,\n",
       "  'know': 596.0,\n",
       "  'oh': 496.0,\n",
       "  'baby': 473.0,\n",
       "  'ill': 459.0,\n",
       "  'dont': 450.0,\n",
       "  '?': 408.0,\n",
       "  'time': 398.0,\n",
       "  'youre': 359.0},\n",
       " 'soul': {'love': 1689.0,\n",
       "  'oh': 1210.0,\n",
       "  'baby': 1194.0,\n",
       "  'dont': 1105.0,\n",
       "  'know': 1058.0,\n",
       "  'im': 1023.0,\n",
       "  'yeah': 1016.0,\n",
       "  '?': 819.0,\n",
       "  'like': 650.0,\n",
       "  'get': 630.0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the top words for each category\n",
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nigga': 1,\n",
       " 'let': 1,\n",
       " 'time': 4,\n",
       " 'well': 1,\n",
       " 'hand': 1,\n",
       " '?': 13,\n",
       " 'im': 14,\n",
       " 'ooh': 1,\n",
       " 'begging': 1,\n",
       " 'like': 11,\n",
       " 'oh': 9,\n",
       " 'one': 2,\n",
       " 'go': 2,\n",
       " 'cant': 1,\n",
       " 'thats': 1,\n",
       " 'got': 4,\n",
       " 'come': 2,\n",
       " 'yeah': 6,\n",
       " 'ill': 1,\n",
       " 'baby': 6,\n",
       " 'take': 1,\n",
       " '!': 4,\n",
       " 'youre': 4,\n",
       " 'aint': 2,\n",
       " 'love': 10,\n",
       " 'plans': 1,\n",
       " 'man': 2,\n",
       " 'see': 1,\n",
       " 'wreck': 1,\n",
       " 'never': 2,\n",
       " 'get': 4,\n",
       " 'dont': 13,\n",
       " 'know': 13}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary of top word frequencies\n",
    "unique_top_words = []\n",
    "for category in top_words:\n",
    "    unique_top_words.extend(top_words[category])\n",
    "unique_top_words = list(set(unique_top_words))\n",
    "\n",
    "top_word_freq = dict.fromkeys(unique_top_words, 0)\n",
    "for category in top_words:\n",
    "    for word in top_words[category]:\n",
    "        top_word_freq[word]+=1\n",
    "top_word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nigga': 1,\n",
       " 'let': 1,\n",
       " 'well': 1,\n",
       " 'hand': 1,\n",
       " 'ooh': 1,\n",
       " 'begging': 1,\n",
       " 'cant': 1,\n",
       " 'thats': 1,\n",
       " 'ill': 1,\n",
       " 'take': 1,\n",
       " 'plans': 1,\n",
       " 'see': 1,\n",
       " 'wreck': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print top words that are unique to one genre\n",
    "dict(filter(lambda key: key[1] == 1, top_word_freq.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'one': 2, 'go': 2, 'come': 2, 'aint': 2, 'man': 2, 'never': 2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print top words that are unique to two genres\n",
    "dict(filter(lambda key: key[1] == 2, top_word_freq.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">blues</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>baby</td>\n",
       "      <td>dont</td>\n",
       "      <td>love</td>\n",
       "      <td>know</td>\n",
       "      <td>got</td>\n",
       "      <td>oh</td>\n",
       "      <td>?</td>\n",
       "      <td>well</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>968</td>\n",
       "      <td>809</td>\n",
       "      <td>768</td>\n",
       "      <td>644</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>486</td>\n",
       "      <td>455</td>\n",
       "      <td>374</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">classical</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>one</td>\n",
       "      <td>come</td>\n",
       "      <td>love</td>\n",
       "      <td>!</td>\n",
       "      <td>dont</td>\n",
       "      <td>get</td>\n",
       "      <td>?</td>\n",
       "      <td>know</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>126</td>\n",
       "      <td>109</td>\n",
       "      <td>105</td>\n",
       "      <td>96</td>\n",
       "      <td>89</td>\n",
       "      <td>87</td>\n",
       "      <td>86</td>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">country</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>like</td>\n",
       "      <td>dont</td>\n",
       "      <td>love</td>\n",
       "      <td>got</td>\n",
       "      <td>yeah</td>\n",
       "      <td>know</td>\n",
       "      <td>oh</td>\n",
       "      <td>aint</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>3013</td>\n",
       "      <td>2460</td>\n",
       "      <td>2382</td>\n",
       "      <td>2025</td>\n",
       "      <td>1959</td>\n",
       "      <td>1935</td>\n",
       "      <td>1908</td>\n",
       "      <td>1887</td>\n",
       "      <td>1712</td>\n",
       "      <td>1645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">funk</th>\n",
       "      <th>words</th>\n",
       "      <td>get</td>\n",
       "      <td>!</td>\n",
       "      <td>baby</td>\n",
       "      <td>love</td>\n",
       "      <td>dont</td>\n",
       "      <td>oh</td>\n",
       "      <td>im</td>\n",
       "      <td>yeah</td>\n",
       "      <td>got</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>986</td>\n",
       "      <td>820</td>\n",
       "      <td>814</td>\n",
       "      <td>783</td>\n",
       "      <td>772</td>\n",
       "      <td>746</td>\n",
       "      <td>680</td>\n",
       "      <td>679</td>\n",
       "      <td>638</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">hiphop</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>like</td>\n",
       "      <td>yeah</td>\n",
       "      <td>nigga</td>\n",
       "      <td>got</td>\n",
       "      <td>dont</td>\n",
       "      <td>?</td>\n",
       "      <td>get</td>\n",
       "      <td>know</td>\n",
       "      <td>aint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>5176</td>\n",
       "      <td>3895</td>\n",
       "      <td>3749</td>\n",
       "      <td>3248</td>\n",
       "      <td>2823</td>\n",
       "      <td>2722</td>\n",
       "      <td>2676</td>\n",
       "      <td>2399</td>\n",
       "      <td>2317</td>\n",
       "      <td>2036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">indie_alt</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>oh</td>\n",
       "      <td>?</td>\n",
       "      <td>dont</td>\n",
       "      <td>know</td>\n",
       "      <td>like</td>\n",
       "      <td>love</td>\n",
       "      <td>youre</td>\n",
       "      <td>time</td>\n",
       "      <td>ooh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>1555</td>\n",
       "      <td>1294</td>\n",
       "      <td>1288</td>\n",
       "      <td>1177</td>\n",
       "      <td>1026</td>\n",
       "      <td>905</td>\n",
       "      <td>776</td>\n",
       "      <td>736</td>\n",
       "      <td>682</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">jazz</th>\n",
       "      <th>words</th>\n",
       "      <td>love</td>\n",
       "      <td>im</td>\n",
       "      <td>dont</td>\n",
       "      <td>know</td>\n",
       "      <td>?</td>\n",
       "      <td>baby</td>\n",
       "      <td>like</td>\n",
       "      <td>let</td>\n",
       "      <td>come</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>490</td>\n",
       "      <td>351</td>\n",
       "      <td>284</td>\n",
       "      <td>231</td>\n",
       "      <td>223</td>\n",
       "      <td>220</td>\n",
       "      <td>206</td>\n",
       "      <td>184</td>\n",
       "      <td>182</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">metal</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>?</td>\n",
       "      <td>!</td>\n",
       "      <td>cant</td>\n",
       "      <td>dont</td>\n",
       "      <td>see</td>\n",
       "      <td>never</td>\n",
       "      <td>one</td>\n",
       "      <td>like</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>1644</td>\n",
       "      <td>1464</td>\n",
       "      <td>1462</td>\n",
       "      <td>887</td>\n",
       "      <td>874</td>\n",
       "      <td>791</td>\n",
       "      <td>774</td>\n",
       "      <td>760</td>\n",
       "      <td>745</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">pop</th>\n",
       "      <th>words</th>\n",
       "      <td>thats</td>\n",
       "      <td>man</td>\n",
       "      <td>take</td>\n",
       "      <td>im</td>\n",
       "      <td>wreck</td>\n",
       "      <td>plans</td>\n",
       "      <td>hand</td>\n",
       "      <td>begging</td>\n",
       "      <td>know</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">punk</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>?</td>\n",
       "      <td>dont</td>\n",
       "      <td>know</td>\n",
       "      <td>like</td>\n",
       "      <td>oh</td>\n",
       "      <td>youre</td>\n",
       "      <td>!</td>\n",
       "      <td>go</td>\n",
       "      <td>never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>1619</td>\n",
       "      <td>1181</td>\n",
       "      <td>1025</td>\n",
       "      <td>843</td>\n",
       "      <td>779</td>\n",
       "      <td>764</td>\n",
       "      <td>669</td>\n",
       "      <td>590</td>\n",
       "      <td>575</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rnb</th>\n",
       "      <th>words</th>\n",
       "      <td>love</td>\n",
       "      <td>oh</td>\n",
       "      <td>yeah</td>\n",
       "      <td>im</td>\n",
       "      <td>baby</td>\n",
       "      <td>dont</td>\n",
       "      <td>know</td>\n",
       "      <td>like</td>\n",
       "      <td>?</td>\n",
       "      <td>youre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>1871</td>\n",
       "      <td>1817</td>\n",
       "      <td>1779</td>\n",
       "      <td>1612</td>\n",
       "      <td>1407</td>\n",
       "      <td>1394</td>\n",
       "      <td>1374</td>\n",
       "      <td>1166</td>\n",
       "      <td>1104</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rock</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>?</td>\n",
       "      <td>dont</td>\n",
       "      <td>oh</td>\n",
       "      <td>like</td>\n",
       "      <td>know</td>\n",
       "      <td>yeah</td>\n",
       "      <td>time</td>\n",
       "      <td>love</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>3547</td>\n",
       "      <td>2629</td>\n",
       "      <td>2580</td>\n",
       "      <td>2502</td>\n",
       "      <td>1964</td>\n",
       "      <td>1889</td>\n",
       "      <td>1689</td>\n",
       "      <td>1480</td>\n",
       "      <td>1472</td>\n",
       "      <td>1416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">romance</th>\n",
       "      <th>words</th>\n",
       "      <td>love</td>\n",
       "      <td>im</td>\n",
       "      <td>know</td>\n",
       "      <td>oh</td>\n",
       "      <td>baby</td>\n",
       "      <td>ill</td>\n",
       "      <td>dont</td>\n",
       "      <td>?</td>\n",
       "      <td>time</td>\n",
       "      <td>youre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>1135</td>\n",
       "      <td>618</td>\n",
       "      <td>596</td>\n",
       "      <td>496</td>\n",
       "      <td>473</td>\n",
       "      <td>459</td>\n",
       "      <td>450</td>\n",
       "      <td>408</td>\n",
       "      <td>398</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">soul</th>\n",
       "      <th>words</th>\n",
       "      <td>love</td>\n",
       "      <td>oh</td>\n",
       "      <td>baby</td>\n",
       "      <td>dont</td>\n",
       "      <td>know</td>\n",
       "      <td>im</td>\n",
       "      <td>yeah</td>\n",
       "      <td>?</td>\n",
       "      <td>like</td>\n",
       "      <td>get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>1689</td>\n",
       "      <td>1210</td>\n",
       "      <td>1194</td>\n",
       "      <td>1105</td>\n",
       "      <td>1058</td>\n",
       "      <td>1023</td>\n",
       "      <td>1016</td>\n",
       "      <td>819</td>\n",
       "      <td>650</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          1     2     3      4      5      6      7        8   \\\n",
       "blues     words           im  baby  dont   love   know    got     oh        ?   \n",
       "          frequencies    968   809   768    644    640    640    486      455   \n",
       "classical words           im   one  come   love      !   dont    get        ?   \n",
       "          frequencies    126   109   105     96     89     87     86       74   \n",
       "country   words           im  like  dont   love    got   yeah   know       oh   \n",
       "          frequencies   3013  2460  2382   2025   1959   1935   1908     1887   \n",
       "funk      words          get     !  baby   love   dont     oh     im     yeah   \n",
       "          frequencies    986   820   814    783    772    746    680      679   \n",
       "hiphop    words           im  like  yeah  nigga    got   dont      ?      get   \n",
       "          frequencies   5176  3895  3749   3248   2823   2722   2676     2399   \n",
       "indie_alt words           im    oh     ?   dont   know   like   love    youre   \n",
       "          frequencies   1555  1294  1288   1177   1026    905    776      736   \n",
       "jazz      words         love    im  dont   know      ?   baby   like      let   \n",
       "          frequencies    490   351   284    231    223    220    206      184   \n",
       "metal     words           im     ?     !   cant   dont    see  never      one   \n",
       "          frequencies   1644  1464  1462    887    874    791    774      760   \n",
       "pop       words        thats   man  take     im  wreck  plans   hand  begging   \n",
       "          frequencies     13    13    11     10      8      8      8        8   \n",
       "punk      words           im     ?  dont   know   like     oh  youre        !   \n",
       "          frequencies   1619  1181  1025    843    779    764    669      590   \n",
       "rnb       words         love    oh  yeah     im   baby   dont   know     like   \n",
       "          frequencies   1871  1817  1779   1612   1407   1394   1374     1166   \n",
       "rock      words           im     ?  dont     oh   like   know   yeah     time   \n",
       "          frequencies   3547  2629  2580   2502   1964   1889   1689     1480   \n",
       "romance   words         love    im  know     oh   baby    ill   dont        ?   \n",
       "          frequencies   1135   618   596    496    473    459    450      408   \n",
       "soul      words         love    oh  baby   dont   know     im   yeah        ?   \n",
       "          frequencies   1689  1210  1194   1105   1058   1023   1016      819   \n",
       "\n",
       "                         9      10  \n",
       "blues     words        well    man  \n",
       "          frequencies   374    350  \n",
       "classical words        know   like  \n",
       "          frequencies    73     71  \n",
       "country   words        aint      ?  \n",
       "          frequencies  1712   1645  \n",
       "funk      words         got      ?  \n",
       "          frequencies   638    632  \n",
       "hiphop    words        know   aint  \n",
       "          frequencies  2317   2036  \n",
       "indie_alt words        time    ooh  \n",
       "          frequencies   682    623  \n",
       "jazz      words        come   time  \n",
       "          frequencies   182    181  \n",
       "metal     words        like   know  \n",
       "          frequencies   745    710  \n",
       "pop       words        know   like  \n",
       "          frequencies     7      7  \n",
       "punk      words          go  never  \n",
       "          frequencies   575    574  \n",
       "rnb       words           ?  youre  \n",
       "          frequencies  1104    794  \n",
       "rock      words        love     go  \n",
       "          frequencies  1472   1416  \n",
       "romance   words        time  youre  \n",
       "          frequencies   398    359  \n",
       "soul      words        like    get  \n",
       "          frequencies   650    630  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame of top ten words\n",
    "categories = np.array(['blues', 'blues', 'classical', 'classical', 'country', 'country', 'funk', \n",
    "              'funk', 'hiphop', 'hiphop', 'indie_alt', 'indie_alt', 'jazz', 'jazz', 'metal',\n",
    "              'metal', 'pop', 'pop', 'punk', 'punk', 'rnb', 'rnb', 'rock', 'rock', \n",
    "              'romance', 'romance', 'soul', 'soul'])\n",
    "arrays = [categories, np.array(['words', 'frequencies', 'words', 'frequencies', 'words', \n",
    "                       'frequencies', 'words', 'frequencies', 'words', 'frequencies', \n",
    "                       'words', 'frequencies', 'words', 'frequencies', 'words',\n",
    "                       'frequencies', 'words', 'frequencies', 'words', 'frequencies', \n",
    "                       'words', 'frequencies', 'words', 'frequencies', 'words', \n",
    "                       'frequencies', 'words', 'frequencies'])]\n",
    "tuples = list(zip(*arrays))\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['genre', 'w/f'])\n",
    "top_ten = pd.DataFrame(df_rows, index=arrays, columns=range(1,11))\n",
    "top_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV\n",
    "top_ten.to_csv('../Data/top_words.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions about top words\n",
    "- From the total 140 top ten words from each of the 14 genres, 29 were unique\n",
    "- 7 out of all the top ten words for each genre are unique to one genre\n",
    "    - 'cant' is unique to the top words in the metal genre\n",
    "    - 'let' is unique to the top words in the jazz genre\n",
    "    - 'nigga' is unique to the hiphop genre\n",
    "    - 'man' and 'well' are unique to the blues genre\n",
    "    - 'see' is unique to the top words in the metal genre\n",
    "    - 'ill' is unique to the top words in the romance genre\n",
    "- 6 out of all the top ten words for each genre are unique to two genre\n",
    "    - 'go' is unique to the top words in the punk and rock genres\n",
    "    - 'aint' is unique to the top words in the country and hiphop genres\n",
    "    - 'come' is unique to the top words in the classical and jazz genres\n",
    "    - 'ooh' is unique to the top words in the indie-alt and pop genres\n",
    "    - 'one' isunique to the top words in the classical and metal genres\n",
    "    - 'never' is unique to the top words in the metal and punk genres\n",
    "- '?', 'dont', and 'im' are in the top ten words for every genre\n",
    "    - 'know' is in the top ten words for every genre except funk\n",
    "    - 'like' and 'love are in the top ten words for 11 out of 14 genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
