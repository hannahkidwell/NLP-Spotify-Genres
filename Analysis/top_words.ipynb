{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 27.488274097442627 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>category_id</th>\n",
       "      <th>genre_list</th>\n",
       "      <th>audio_ft_danceability</th>\n",
       "      <th>audio_ft_energy</th>\n",
       "      <th>audio_ft_key</th>\n",
       "      <th>audio_ft_mode</th>\n",
       "      <th>audio_ft_speechiness</th>\n",
       "      <th>...</th>\n",
       "      <th>entirely</th>\n",
       "      <th>basket</th>\n",
       "      <th>car</th>\n",
       "      <th>shawn</th>\n",
       "      <th>nothingness</th>\n",
       "      <th>amused</th>\n",
       "      <th>corners</th>\n",
       "      <th>interlude</th>\n",
       "      <th>sting</th>\n",
       "      <th>axis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-2</th>\n",
       "      <td>8015</td>\n",
       "      <td>8015</td>\n",
       "      <td>8015</td>\n",
       "      <td>7592.0</td>\n",
       "      <td>8015</td>\n",
       "      <td>8015.0000</td>\n",
       "      <td>8015.0000</td>\n",
       "      <td>7150.0</td>\n",
       "      <td>5501.0</td>\n",
       "      <td>8015.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53368.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4518.1163</td>\n",
       "      <td>5348.9565</td>\n",
       "      <td>42484.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>664.1198</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>willow</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>pop</td>\n",
       "      <td>8.0</td>\n",
       "      <td>['dance', 'pop']</td>\n",
       "      <td>0.3920</td>\n",
       "      <td>0.5740</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stay Next To Me (with Chelsea Cutler)</td>\n",
       "      <td>Quinn XCII</td>\n",
       "      <td>pop</td>\n",
       "      <td>8.0</td>\n",
       "      <td>['indie', 'pop', 'electropop']</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>0.5840</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WITHOUT YOU</td>\n",
       "      <td>The Kid LAROI</td>\n",
       "      <td>pop</td>\n",
       "      <td>8.0</td>\n",
       "      <td>['australian']</td>\n",
       "      <td>0.6620</td>\n",
       "      <td>0.4130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 12025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                song_name    artist_name category_name  \\\n",
       "-2                                   8015           8015          8015   \n",
       "-1                                    NaN            NaN           NaN   \n",
       "0                                  willow   Taylor Swift           pop   \n",
       "1   Stay Next To Me (with Chelsea Cutler)     Quinn XCII           pop   \n",
       "2                             WITHOUT YOU  The Kid LAROI           pop   \n",
       "\n",
       "    category_id                      genre_list  audio_ft_danceability  \\\n",
       "-2       7592.0                            8015              8015.0000   \n",
       "-1      53368.0                             NaN              4518.1163   \n",
       "0           8.0                ['dance', 'pop']                 0.3920   \n",
       "1           8.0  ['indie', 'pop', 'electropop']                 0.5810   \n",
       "2           8.0                  ['australian']                 0.6620   \n",
       "\n",
       "    audio_ft_energy  audio_ft_key  audio_ft_mode  audio_ft_speechiness  ...  \\\n",
       "-2        8015.0000        7150.0         5501.0             8015.0000  ...   \n",
       "-1        5348.9565       42484.0         5500.0              664.1198  ...   \n",
       "0            0.5740           7.0            1.0                0.1700  ...   \n",
       "1            0.5840           2.0            1.0                0.2840  ...   \n",
       "2            0.4130           0.0            1.0                0.0299  ...   \n",
       "\n",
       "    entirely  basket    car  shawn  nothingness  amused  corners  interlude  \\\n",
       "-2       5.0    11.0  385.0    7.0          9.0     6.0     24.0        8.0   \n",
       "-1       5.0    14.0  681.0    7.0         10.0     7.0     31.0        7.0   \n",
       "0        0.0     0.0    0.0    0.0          0.0     0.0      0.0        0.0   \n",
       "1        0.0     0.0    0.0    0.0          0.0     0.0      0.0        0.0   \n",
       "2        0.0     0.0    0.0    0.0          0.0     0.0      0.0        0.0   \n",
       "\n",
       "    sting  axis  \n",
       "-2   34.0   5.0  \n",
       "-1   49.0   4.0  \n",
       "0     0.0   0.0  \n",
       "1     0.0   0.0  \n",
       "2     0.0   0.0  \n",
       "\n",
       "[5 rows x 12025 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame from CSV\n",
    "t0 = time.time()\n",
    "filtered_lyric_TF_df = pd.read_csv('../Data/filtered_lyric_TF.csv')\n",
    "#filtered_lyric_TF_df = filtered_lyric_TF_df.drop([0,1])\n",
    "filtered_lyric_TF_df.index = filtered_lyric_TF_df.index - 2\n",
    "t1 = time.time()\n",
    "print(f'Run time: {t1-t0} seconds')\n",
    "filtered_lyric_TF_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blues 0.0\n",
      "classical 1.0\n",
      "country 2.0\n",
      "funk 3.0\n",
      "hiphop 4.0\n",
      "indie_alt 5.0\n",
      "jazz 6.0\n",
      "metal 7.0\n",
      "pop 8.0\n",
      "punk 9.0\n",
      "rnb 10.0\n",
      "rock 11.0\n",
      "romance 12.0\n",
      "soul 13.0\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary of category names and ids\n",
    "cat_name_id = {}\n",
    "category_list = ['blues', 'classical', 'country', 'funk', 'hiphop', 'indie_alt', 'jazz', \n",
    "                 'metal', 'pop', 'punk', 'rnb', 'rock', 'romance', 'soul']\n",
    "for cat in category_list:\n",
    "    cat_id = list(filtered_lyric_TF_df[filtered_lyric_TF_df['category_name']==cat]['category_id'])[0]\n",
    "    cat_name_id[cat] = cat_id\n",
    "    print(cat, cat_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame and combine the columns for 'nigga' and 'niggas'\n",
    "new_lyric_TF_df = filtered_lyric_TF_df.drop([-2, -1])\n",
    "for i in range(len(new_lyric_TF_df)):\n",
    "    new_lyric_TF_df.at[i, 'nigga'] = new_lyric_TF_df.at[i, 'nigga'] + new_lyric_TF_df.at[i, 'niggas']\n",
    "new_lyric_TF_df = new_lyric_TF_df.drop('niggas', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'im': 25280.0,\n",
       " 'dont': 17907.0,\n",
       " '?': 16604.0,\n",
       " 'like': 16012.0,\n",
       " 'know': 15030.0,\n",
       " 'oh': 14976.0,\n",
       " 'yeah': 14800.0,\n",
       " 'love': 14119.0,\n",
       " 'got': 11280.0,\n",
       " 'get': 10844.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of the overall top ten words \n",
    "word_count_df = filtered_lyric_TF_df[1:2][filtered_lyric_TF_df.columns[17:]]\n",
    "word_count_df = word_count_df.sort_values(by=[-1], axis=1, ascending=False)\n",
    "top_word_counts = list(word_count_df.loc[-1])[0:10]\n",
    "top_ten = dict(zip(list(word_count_df)[0:10], top_word_counts))\n",
    "top_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['im',\n",
       " 'dont',\n",
       " '?',\n",
       " 'like',\n",
       " 'know',\n",
       " 'oh',\n",
       " 'yeah',\n",
       " 'love',\n",
       " 'got',\n",
       " 'get',\n",
       " 'baby',\n",
       " 'youre',\n",
       " 'go',\n",
       " 'time',\n",
       " 'cant',\n",
       " 'one',\n",
       " 'never',\n",
       " 'cause',\n",
       " 'wanna',\n",
       " 'see',\n",
       " 'come',\n",
       " 'let',\n",
       " 'back',\n",
       " 'want',\n",
       " 'aint']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_twentyfive_words = list(word_count_df)[0:25]\n",
    "top_twentyfive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>song_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>category</th>\n",
       "      <th>category_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>genres</th>\n",
       "      <th>audio_ft_danceability</th>\n",
       "      <th>audio_ft_energy</th>\n",
       "      <th>...</th>\n",
       "      <th>audio_ft_liveness</th>\n",
       "      <th>audio_ft_valence</th>\n",
       "      <th>audio_ft_tempo</th>\n",
       "      <th>audio_ft_duration_ms</th>\n",
       "      <th>audio_ft_time_signature</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>non_alpha_words</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>willow</td>\n",
       "      <td>0lx2cLdOt3piJbcaXIV74f</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>06HL4z0CvFAxyc27GXpf02</td>\n",
       "      <td>pop</td>\n",
       "      <td>8</td>\n",
       "      <td>93</td>\n",
       "      <td>['dance', 'pop']</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.529</td>\n",
       "      <td>81.112</td>\n",
       "      <td>214707.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Im like the water when your ship rolled in th...</td>\n",
       "      <td>1</td>\n",
       "      <td>['', 'im', 'like', 'the', 'water', 'when', 'yo...</td>\n",
       "      <td>['', 'im', 'like', 'water', 'ship', 'rolled', ...</td>\n",
       "      <td>(1, 'en')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stay Next To Me (with Chelsea Cutler)</td>\n",
       "      <td>6SGG5AxHShqSYiV9fCWpZz</td>\n",
       "      <td>Quinn XCII</td>\n",
       "      <td>3ApUX1o6oSz321MMECyIYd</td>\n",
       "      <td>pop</td>\n",
       "      <td>8</td>\n",
       "      <td>78</td>\n",
       "      <td>['indie', 'pop', 'electropop']</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3660</td>\n",
       "      <td>0.756</td>\n",
       "      <td>179.954</td>\n",
       "      <td>206046.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Didnt even wanna go out whyd you call me ? Iv...</td>\n",
       "      <td>1</td>\n",
       "      <td>['', 'didnt', 'even', 'wanna', 'go', 'out', 'w...</td>\n",
       "      <td>['', 'didnt', 'even', 'wanna', 'go', 'whyd', '...</td>\n",
       "      <td>(1, 'en')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WITHOUT YOU</td>\n",
       "      <td>27OeeYzk6klgBh83TSvGMA</td>\n",
       "      <td>The Kid LAROI</td>\n",
       "      <td>2tIP7SsRs7vjIcLrU85W8J</td>\n",
       "      <td>pop</td>\n",
       "      <td>8</td>\n",
       "      <td>95</td>\n",
       "      <td>['australian']</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.467</td>\n",
       "      <td>93.005</td>\n",
       "      <td>161385.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>You cut out a piece of me and now I bleed int...</td>\n",
       "      <td>1</td>\n",
       "      <td>['', 'you', 'cut', 'out', 'a', 'piece', 'of', ...</td>\n",
       "      <td>['', 'cut', 'piece', 'bleed', 'internally', 'l...</td>\n",
       "      <td>(1, 'en')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heat Waves</td>\n",
       "      <td>3USxtqRwSYz57Ewm6wWRMp</td>\n",
       "      <td>Glass Animals</td>\n",
       "      <td>4yvcSjfu4PC0CYQyLy4wSq</td>\n",
       "      <td>pop</td>\n",
       "      <td>8</td>\n",
       "      <td>81</td>\n",
       "      <td>['shiver', 'indietronica', 'gauze']</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.531</td>\n",
       "      <td>80.870</td>\n",
       "      <td>238805.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Last night all I think about is you Dont stop...</td>\n",
       "      <td>1</td>\n",
       "      <td>['', 'last', 'night', 'all', 'i', 'think', 'ab...</td>\n",
       "      <td>['', 'last', 'night', 'think', 'dont', 'stop',...</td>\n",
       "      <td>(1, 'en')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r u ok</td>\n",
       "      <td>7rq1zCf90CnU7OalBLIgNp</td>\n",
       "      <td>Tate McRae</td>\n",
       "      <td>45dkTj5sMRSjrmBSBeiHym</td>\n",
       "      <td>pop</td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>['dance', 'pop', 'electropop', 'post-teen']</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4140</td>\n",
       "      <td>0.329</td>\n",
       "      <td>140.013</td>\n",
       "      <td>185850.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Are you okay ? Cause youre the one who needed...</td>\n",
       "      <td>1</td>\n",
       "      <td>['', 'are', 'you', 'okay', '?', 'cause', 'your...</td>\n",
       "      <td>['', 'okay', '?', 'cause', 'youre', 'one', 'ne...</td>\n",
       "      <td>(1, 'en')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    song                 song_id  \\\n",
       "0                                 willow  0lx2cLdOt3piJbcaXIV74f   \n",
       "1  Stay Next To Me (with Chelsea Cutler)  6SGG5AxHShqSYiV9fCWpZz   \n",
       "2                            WITHOUT YOU  27OeeYzk6klgBh83TSvGMA   \n",
       "3                             Heat Waves  3USxtqRwSYz57Ewm6wWRMp   \n",
       "4                                 r u ok  7rq1zCf90CnU7OalBLIgNp   \n",
       "\n",
       "          artist               artist_id category  category_id  popularity  \\\n",
       "0   Taylor Swift  06HL4z0CvFAxyc27GXpf02      pop            8          93   \n",
       "1     Quinn XCII  3ApUX1o6oSz321MMECyIYd      pop            8          78   \n",
       "2  The Kid LAROI  2tIP7SsRs7vjIcLrU85W8J      pop            8          95   \n",
       "3  Glass Animals  4yvcSjfu4PC0CYQyLy4wSq      pop            8          81   \n",
       "4     Tate McRae  45dkTj5sMRSjrmBSBeiHym      pop            8          80   \n",
       "\n",
       "                                        genres  audio_ft_danceability  \\\n",
       "0                             ['dance', 'pop']                  0.392   \n",
       "1               ['indie', 'pop', 'electropop']                  0.581   \n",
       "2                               ['australian']                  0.662   \n",
       "3          ['shiver', 'indietronica', 'gauze']                  0.761   \n",
       "4  ['dance', 'pop', 'electropop', 'post-teen']                  0.666   \n",
       "\n",
       "   audio_ft_energy  ...  audio_ft_liveness  audio_ft_valence  audio_ft_tempo  \\\n",
       "0            0.574  ...             0.1450             0.529          81.112   \n",
       "1            0.584  ...             0.3660             0.756         179.954   \n",
       "2            0.413  ...             0.1340             0.467          93.005   \n",
       "3            0.525  ...             0.0921             0.531          80.870   \n",
       "4            0.593  ...             0.4140             0.329         140.013   \n",
       "\n",
       "   audio_ft_duration_ms  audio_ft_time_signature  \\\n",
       "0              214707.0                      4.0   \n",
       "1              206046.0                      4.0   \n",
       "2              161385.0                      4.0   \n",
       "3              238805.0                      4.0   \n",
       "4              185850.0                      4.0   \n",
       "\n",
       "                                              lyrics  non_alpha_words  \\\n",
       "0   Im like the water when your ship rolled in th...                1   \n",
       "1   Didnt even wanna go out whyd you call me ? Iv...                1   \n",
       "2   You cut out a piece of me and now I bleed int...                1   \n",
       "3   Last night all I think about is you Dont stop...                1   \n",
       "4   Are you okay ? Cause youre the one who needed...                1   \n",
       "\n",
       "                                               words  \\\n",
       "0  ['', 'im', 'like', 'the', 'water', 'when', 'yo...   \n",
       "1  ['', 'didnt', 'even', 'wanna', 'go', 'out', 'w...   \n",
       "2  ['', 'you', 'cut', 'out', 'a', 'piece', 'of', ...   \n",
       "3  ['', 'last', 'night', 'all', 'i', 'think', 'ab...   \n",
       "4  ['', 'are', 'you', 'okay', '?', 'cause', 'your...   \n",
       "\n",
       "                                            filtered   language  \n",
       "0  ['', 'im', 'like', 'water', 'ship', 'rolled', ...  (1, 'en')  \n",
       "1  ['', 'didnt', 'even', 'wanna', 'go', 'whyd', '...  (1, 'en')  \n",
       "2  ['', 'cut', 'piece', 'bleed', 'internally', 'l...  (1, 'en')  \n",
       "3  ['', 'last', 'night', 'think', 'dont', 'stop',...  (1, 'en')  \n",
       "4  ['', 'okay', '?', 'cause', 'youre', 'one', 'ne...  (1, 'en')  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lyrics = pd.read_csv('../Data/nlp_df.csv')\n",
    "all_lyrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92148\n"
     ]
    }
   ],
   "source": [
    "# Counting word in filtered category df\n",
    "df = all_lyrics[all_lyrics['category']=='blues'].copy()\n",
    "df = pd.DataFrame(df, columns=['category','words'])\n",
    "\n",
    "substr = \",\"\n",
    "print (df.words.str.count(substr).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35882\n"
     ]
    }
   ],
   "source": [
    "# Counting word in filtered category df\n",
    "df = all_lyrics[all_lyrics['category']=='classical'].copy()\n",
    "df = pd.DataFrame(df, columns=['category','words'])\n",
    "\n",
    "substr = \",\"\n",
    "print (df.words.str.count(substr).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377687\n"
     ]
    }
   ],
   "source": [
    "# Counting word in filtered category df\n",
    "df = all_lyrics[all_lyrics['category']=='country'].copy()\n",
    "df = pd.DataFrame(df, columns=['category','words'])\n",
    "\n",
    "substr = \",\"\n",
    "print (df.words.str.count(substr).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102058\n"
     ]
    }
   ],
   "source": [
    "# Counting word in filtered category df\n",
    "df = all_lyrics[all_lyrics['category']=='funk'].copy()\n",
    "df = pd.DataFrame(df, columns=['category','words'])\n",
    "\n",
    "substr = \",\"\n",
    "print (df.words.str.count(substr).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413581\n"
     ]
    }
   ],
   "source": [
    "# Counting word in filtered category df\n",
    "df = all_lyrics[all_lyrics['category']=='hiphop'].copy()\n",
    "df = pd.DataFrame(df, columns=['category','words'])\n",
    "\n",
    "substr = \",\"\n",
    "print (df.words.str.count(substr).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174576\n"
     ]
    }
   ],
   "source": [
    "# Counting word in filtered category df\n",
    "df = all_lyrics[all_lyrics['category']=='indie_alt'].copy()\n",
    "df = pd.DataFrame(df, columns=['category','words'])\n",
    "\n",
    "substr = \",\"\n",
    "print (df.words.str.count(substr).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47916\n"
     ]
    }
   ],
   "source": [
    "# Counting word in filtered category df\n",
    "df = all_lyrics[all_lyrics['category']=='jazz'].copy()\n",
    "df = pd.DataFrame(df, columns=['category','words'])\n",
    "\n",
    "substr = \",\"\n",
    "print (df.words.str.count(substr).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236760\n"
     ]
    }
   ],
   "source": [
    "# Counting word in filtered category df\n",
    "df = all_lyrics[all_lyrics['category']=='metal'].copy()\n",
    "df = pd.DataFrame(df, columns=['category','words'])\n",
    "\n",
    "substr = \",\"\n",
    "print (df.words.str.count(substr).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239795\n"
     ]
    }
   ],
   "source": [
    "# Counting word in filtered category df\n",
    "df = all_lyrics[all_lyrics['category']=='pop'].copy()\n",
    "df = pd.DataFrame(df, columns=['category','words'])\n",
    "\n",
    "substr = \",\"\n",
    "print (df.words.str.count(substr).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161710\n"
     ]
    }
   ],
   "source": [
    "# Counting word in filtered category df\n",
    "df = all_lyrics[all_lyrics['category']=='punk'].copy()\n",
    "df = pd.DataFrame(df, columns=['category','words'])\n",
    "\n",
    "substr = \",\"\n",
    "print (df.words.str.count(substr).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152850\n"
     ]
    }
   ],
   "source": [
    "# Counting word in filtered category df\n",
    "df = all_lyrics[all_lyrics['category']=='rnb'].copy()\n",
    "df = pd.DataFrame(df, columns=['category','words'])\n",
    "\n",
    "substr = \",\"\n",
    "print (df.words.str.count(substr).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357875\n"
     ]
    }
   ],
   "source": [
    "# Counting word in filtered category df\n",
    "df = all_lyrics[all_lyrics['category']=='rock'].copy()\n",
    "df = pd.DataFrame(df, columns=['category','words'])\n",
    "\n",
    "substr = \",\"\n",
    "print (df.words.str.count(substr).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117316\n"
     ]
    }
   ],
   "source": [
    "# Counting word in filtered category df\n",
    "df = all_lyrics[all_lyrics['category']=='romance'].copy()\n",
    "df = pd.DataFrame(df, columns=['category','words'])\n",
    "\n",
    "substr = \",\"\n",
    "print (df.words.str.count(substr).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132664\n"
     ]
    }
   ],
   "source": [
    "# Counting word in filtered category df\n",
    "df = all_lyrics[all_lyrics['category']=='soul'].copy()\n",
    "df = pd.DataFrame(df, columns=['category','words'])\n",
    "\n",
    "substr = \",\"\n",
    "print (df.words.str.count(substr).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1155\n"
     ]
    }
   ],
   "source": [
    "substr = 'know'\n",
    "print (df.filtered.str.count(substr).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 3.994533061981201 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary of the top ten words for each category\n",
    "t0 = time.time()\n",
    "top_words = {}\n",
    "df_rows = []\n",
    "blues_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='blues'].copy()\n",
    "blues_df.loc[0] = blues_df.sum(numeric_only=True)\n",
    "blues_words = blues_df.sort_index()[blues_df.columns[17:]][0:1]\n",
    "blues_words = blues_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(blues_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(blues_words)[0:10], top_word_counts))\n",
    "top_words['blues'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "classical_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='classical'].copy()\n",
    "classical_df.loc[0] = classical_df.sum(numeric_only=True)\n",
    "classical_words = classical_df.sort_index()[classical_df.columns[17:]][0:1]\n",
    "classical_words = classical_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(classical_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(classical_words), top_word_counts))\n",
    "top_words['classical'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "country_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='country'].copy()\n",
    "country_df.loc[0] = country_df.sum(numeric_only=True)\n",
    "country_words = country_df.sort_index()[country_df.columns[17:]][0:1]\n",
    "country_words = country_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(country_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(country_words)[0:10], top_word_counts))\n",
    "top_words['country'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "funk_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='funk'].copy()\n",
    "funk_df.loc[0] = funk_df.sum(numeric_only=True)\n",
    "funk_words = funk_df.sort_index()[funk_df.columns[17:]][0:1]\n",
    "funk_words = funk_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(funk_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(funk_words)[0:10], top_word_counts))\n",
    "top_words['funk'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "hiphop_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='hiphop'].copy()\n",
    "hiphop_df.loc[0] = hiphop_df.sum(numeric_only=True)\n",
    "hiphop_words = hiphop_df.sort_index()[hiphop_df.columns[17:]][0:1]\n",
    "hiphop_words = hiphop_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(hiphop_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(hiphop_words)[0:10], top_word_counts))\n",
    "top_words['hiphop'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "indie_alt_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='indie_alt'].copy()\n",
    "indie_alt_df.loc[0] = indie_alt_df.sum(numeric_only=True)\n",
    "indie_alt_words = indie_alt_df.sort_index()[indie_alt_df.columns[17:]][0:1]\n",
    "indie_alt_words = indie_alt_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(indie_alt_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(indie_alt_words)[0:10], top_word_counts))\n",
    "top_words['indie_alt'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "jazz_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='jazz'].copy()\n",
    "jazz_df.loc[0] = jazz_df.sum(numeric_only=True)\n",
    "jazz_words = jazz_df.sort_index()[jazz_df.columns[17:]][0:1]\n",
    "jazz_words = jazz_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(jazz_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(jazz_words)[0:10], top_word_counts))\n",
    "top_words['jazz'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "metal_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='metal'].copy()\n",
    "metal_df.loc[0] = metal_df.sum(numeric_only=True)\n",
    "metal_words = metal_df.sort_index()[metal_df.columns[17:]][0:1]\n",
    "metal_words = metal_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(metal_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(metal_words)[0:10], top_word_counts))\n",
    "top_words['metal'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "pop_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='pop'].copy()\n",
    "pop_df.loc[-1] = pop_df.sum(numeric_only=True)\n",
    "pop_words = pop_df.sort_index()[pop_df.columns[17:]]\n",
    "pop_words = pop_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(pop_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(pop_words)[0:10], top_word_counts))\n",
    "top_words['pop'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "punk_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='punk'].copy()\n",
    "punk_df.loc[0] = punk_df.sum(numeric_only=True)\n",
    "punk_words = punk_df.sort_index()[punk_df.columns[17:]][0:1]\n",
    "punk_words = punk_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(punk_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(punk_words)[0:10], top_word_counts))\n",
    "top_words['punk'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "rnb_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='rnb'].copy()\n",
    "rnb_df.loc[0] = rnb_df.sum(numeric_only=True)\n",
    "rnb_words = rnb_df.sort_index()[rnb_df.columns[17:]][0:1]\n",
    "rnb_words = rnb_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(rnb_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(rnb_words)[0:10], top_word_counts))\n",
    "top_words['rnb'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "rock_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='rock'].copy()\n",
    "rock_df.loc[0] = rock_df.sum(numeric_only=True)\n",
    "rock_words = rock_df.sort_index()[rock_df.columns[17:]][0:1]\n",
    "rock_words = rock_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(rock_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(rock_words)[0:10], top_word_counts))\n",
    "top_words['rock'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "romance_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='romance'].copy()\n",
    "romance_df.loc[0] = romance_df.sum(numeric_only=True)\n",
    "romance_words = romance_df.sort_index()[romance_df.columns[17:]][0:1]\n",
    "romance_words = romance_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(romance_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(romance_words)[0:10], top_word_counts))\n",
    "top_words['romance'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "soul_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='soul'].copy()\n",
    "soul_df.loc[0] = soul_df.sum(numeric_only=True)\n",
    "soul_words = soul_df.sort_index()[soul_df.columns[17:]][0:1]\n",
    "soul_words = soul_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(soul_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(soul_words)[0:10], top_word_counts))\n",
    "top_words['soul'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "t1 = time.time()\n",
    "print(f'Run time: {t1-t0} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blues': {'im': 968.0,\n",
       "  'baby': 809.0,\n",
       "  'dont': 768.0,\n",
       "  'love': 644.0,\n",
       "  'know': 640.0,\n",
       "  'got': 640.0,\n",
       "  'oh': 486.0,\n",
       "  '?': 455.0,\n",
       "  'well': 374.0,\n",
       "  'man': 350.0},\n",
       " 'classical': {'im': 126.0,\n",
       "  'one': 109.0,\n",
       "  'come': 105.0,\n",
       "  'love': 96.0,\n",
       "  '!': 89.0,\n",
       "  'dont': 87.0,\n",
       "  'get': 86.0,\n",
       "  '?': 74.0,\n",
       "  'know': 73.0,\n",
       "  'like': 71.0},\n",
       " 'country': {'im': 3013.0,\n",
       "  'like': 2460.0,\n",
       "  'dont': 2382.0,\n",
       "  'love': 2025.0,\n",
       "  'got': 1959.0,\n",
       "  'yeah': 1935.0,\n",
       "  'know': 1908.0,\n",
       "  'oh': 1887.0,\n",
       "  'aint': 1712.0,\n",
       "  '?': 1645.0},\n",
       " 'funk': {'get': 986.0,\n",
       "  '!': 820.0,\n",
       "  'baby': 814.0,\n",
       "  'love': 783.0,\n",
       "  'dont': 772.0,\n",
       "  'oh': 746.0,\n",
       "  'im': 680.0,\n",
       "  'yeah': 679.0,\n",
       "  'got': 638.0,\n",
       "  '?': 632.0},\n",
       " 'hiphop': {'im': 5176.0,\n",
       "  'like': 3895.0,\n",
       "  'yeah': 3749.0,\n",
       "  'nigga': 3248.0,\n",
       "  'got': 2823.0,\n",
       "  'dont': 2722.0,\n",
       "  '?': 2676.0,\n",
       "  'get': 2399.0,\n",
       "  'know': 2317.0,\n",
       "  'aint': 2036.0},\n",
       " 'indie_alt': {'im': 1555.0,\n",
       "  'oh': 1294.0,\n",
       "  '?': 1288.0,\n",
       "  'dont': 1177.0,\n",
       "  'know': 1026.0,\n",
       "  'like': 905.0,\n",
       "  'love': 776.0,\n",
       "  'youre': 736.0,\n",
       "  'time': 682.0,\n",
       "  'ooh': 623.0},\n",
       " 'jazz': {'love': 490.0,\n",
       "  'im': 351.0,\n",
       "  'dont': 284.0,\n",
       "  'know': 231.0,\n",
       "  '?': 223.0,\n",
       "  'baby': 220.0,\n",
       "  'like': 206.0,\n",
       "  'let': 184.0,\n",
       "  'come': 182.0,\n",
       "  'time': 181.0},\n",
       " 'metal': {'im': 1644.0,\n",
       "  '?': 1464.0,\n",
       "  '!': 1462.0,\n",
       "  'cant': 887.0,\n",
       "  'dont': 874.0,\n",
       "  'see': 791.0,\n",
       "  'never': 774.0,\n",
       "  'one': 760.0,\n",
       "  'like': 745.0,\n",
       "  'know': 710.0},\n",
       " 'pop': {'thats': 13.0,\n",
       "  'man': 13.0,\n",
       "  'take': 11.0,\n",
       "  'im': 10.0,\n",
       "  'wreck': 8.0,\n",
       "  'plans': 8.0,\n",
       "  'hand': 8.0,\n",
       "  'begging': 8.0,\n",
       "  'know': 7.0,\n",
       "  'like': 7.0},\n",
       " 'punk': {'im': 1619.0,\n",
       "  '?': 1181.0,\n",
       "  'dont': 1025.0,\n",
       "  'know': 843.0,\n",
       "  'like': 779.0,\n",
       "  'oh': 764.0,\n",
       "  'youre': 669.0,\n",
       "  '!': 590.0,\n",
       "  'go': 575.0,\n",
       "  'never': 574.0},\n",
       " 'rnb': {'love': 1871.0,\n",
       "  'oh': 1817.0,\n",
       "  'yeah': 1779.0,\n",
       "  'im': 1612.0,\n",
       "  'baby': 1407.0,\n",
       "  'dont': 1394.0,\n",
       "  'know': 1374.0,\n",
       "  'like': 1166.0,\n",
       "  '?': 1104.0,\n",
       "  'youre': 794.0},\n",
       " 'rock': {'im': 3547.0,\n",
       "  '?': 2629.0,\n",
       "  'dont': 2580.0,\n",
       "  'oh': 2502.0,\n",
       "  'like': 1964.0,\n",
       "  'know': 1889.0,\n",
       "  'yeah': 1689.0,\n",
       "  'time': 1480.0,\n",
       "  'love': 1472.0,\n",
       "  'go': 1416.0},\n",
       " 'romance': {'love': 1135.0,\n",
       "  'im': 618.0,\n",
       "  'know': 596.0,\n",
       "  'oh': 496.0,\n",
       "  'baby': 473.0,\n",
       "  'ill': 459.0,\n",
       "  'dont': 450.0,\n",
       "  '?': 408.0,\n",
       "  'time': 398.0,\n",
       "  'youre': 359.0},\n",
       " 'soul': {'love': 1689.0,\n",
       "  'oh': 1210.0,\n",
       "  'baby': 1194.0,\n",
       "  'dont': 1105.0,\n",
       "  'know': 1058.0,\n",
       "  'im': 1023.0,\n",
       "  'yeah': 1016.0,\n",
       "  '?': 819.0,\n",
       "  'like': 650.0,\n",
       "  'get': 630.0}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the top words for each category\n",
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plans': 1,\n",
       " 'one': 2,\n",
       " 'cant': 1,\n",
       " 'go': 2,\n",
       " 'yeah': 6,\n",
       " 'im': 14,\n",
       " 'baby': 6,\n",
       " 'oh': 9,\n",
       " 'like': 11,\n",
       " 'dont': 13,\n",
       " '!': 4,\n",
       " 'love': 10,\n",
       " 'come': 2,\n",
       " '?': 13,\n",
       " 'got': 4,\n",
       " 'know': 13,\n",
       " 'nigga': 1,\n",
       " 'wreck': 1,\n",
       " 'get': 4,\n",
       " 'aint': 2,\n",
       " 'let': 1,\n",
       " 'see': 1,\n",
       " 'well': 1,\n",
       " 'ill': 1,\n",
       " 'thats': 1,\n",
       " 'begging': 1,\n",
       " 'hand': 1,\n",
       " 'take': 1,\n",
       " 'time': 4,\n",
       " 'man': 2,\n",
       " 'youre': 4,\n",
       " 'never': 2,\n",
       " 'ooh': 1}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary of top word frequencies\n",
    "unique_top_words = []\n",
    "for category in top_words:\n",
    "    unique_top_words.extend(top_words[category])\n",
    "unique_top_words = list(set(unique_top_words))\n",
    "\n",
    "top_word_freq = dict.fromkeys(unique_top_words, 0)\n",
    "for category in top_words:\n",
    "    for word in top_words[category]:\n",
    "        top_word_freq[word]+=1\n",
    "top_word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plans': 1,\n",
       " 'cant': 1,\n",
       " 'nigga': 1,\n",
       " 'wreck': 1,\n",
       " 'let': 1,\n",
       " 'see': 1,\n",
       " 'well': 1,\n",
       " 'ill': 1,\n",
       " 'thats': 1,\n",
       " 'begging': 1,\n",
       " 'hand': 1,\n",
       " 'take': 1,\n",
       " 'ooh': 1}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print top words that are unique to one genre\n",
    "dict(filter(lambda key: key[1] == 1, top_word_freq.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'one': 2, 'go': 2, 'come': 2, 'aint': 2, 'man': 2, 'never': 2}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print top words that are unique to two genre\n",
    "dict(filter(lambda key: key[1] == 2, top_word_freq.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">blues</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>baby</td>\n",
       "      <td>dont</td>\n",
       "      <td>love</td>\n",
       "      <td>know</td>\n",
       "      <td>got</td>\n",
       "      <td>oh</td>\n",
       "      <td>?</td>\n",
       "      <td>well</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>968</td>\n",
       "      <td>809</td>\n",
       "      <td>768</td>\n",
       "      <td>644</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>486</td>\n",
       "      <td>455</td>\n",
       "      <td>374</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">classical</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>one</td>\n",
       "      <td>come</td>\n",
       "      <td>love</td>\n",
       "      <td>!</td>\n",
       "      <td>dont</td>\n",
       "      <td>get</td>\n",
       "      <td>?</td>\n",
       "      <td>know</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>126</td>\n",
       "      <td>109</td>\n",
       "      <td>105</td>\n",
       "      <td>96</td>\n",
       "      <td>89</td>\n",
       "      <td>87</td>\n",
       "      <td>86</td>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">country</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>like</td>\n",
       "      <td>dont</td>\n",
       "      <td>love</td>\n",
       "      <td>got</td>\n",
       "      <td>yeah</td>\n",
       "      <td>know</td>\n",
       "      <td>oh</td>\n",
       "      <td>aint</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>3013</td>\n",
       "      <td>2460</td>\n",
       "      <td>2382</td>\n",
       "      <td>2025</td>\n",
       "      <td>1959</td>\n",
       "      <td>1935</td>\n",
       "      <td>1908</td>\n",
       "      <td>1887</td>\n",
       "      <td>1712</td>\n",
       "      <td>1645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">funk</th>\n",
       "      <th>words</th>\n",
       "      <td>get</td>\n",
       "      <td>!</td>\n",
       "      <td>baby</td>\n",
       "      <td>love</td>\n",
       "      <td>dont</td>\n",
       "      <td>oh</td>\n",
       "      <td>im</td>\n",
       "      <td>yeah</td>\n",
       "      <td>got</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>986</td>\n",
       "      <td>820</td>\n",
       "      <td>814</td>\n",
       "      <td>783</td>\n",
       "      <td>772</td>\n",
       "      <td>746</td>\n",
       "      <td>680</td>\n",
       "      <td>679</td>\n",
       "      <td>638</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">hiphop</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>like</td>\n",
       "      <td>yeah</td>\n",
       "      <td>nigga</td>\n",
       "      <td>got</td>\n",
       "      <td>dont</td>\n",
       "      <td>?</td>\n",
       "      <td>get</td>\n",
       "      <td>know</td>\n",
       "      <td>aint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>5176</td>\n",
       "      <td>3895</td>\n",
       "      <td>3749</td>\n",
       "      <td>3248</td>\n",
       "      <td>2823</td>\n",
       "      <td>2722</td>\n",
       "      <td>2676</td>\n",
       "      <td>2399</td>\n",
       "      <td>2317</td>\n",
       "      <td>2036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">indie_alt</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>oh</td>\n",
       "      <td>?</td>\n",
       "      <td>dont</td>\n",
       "      <td>know</td>\n",
       "      <td>like</td>\n",
       "      <td>love</td>\n",
       "      <td>youre</td>\n",
       "      <td>time</td>\n",
       "      <td>ooh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>1555</td>\n",
       "      <td>1294</td>\n",
       "      <td>1288</td>\n",
       "      <td>1177</td>\n",
       "      <td>1026</td>\n",
       "      <td>905</td>\n",
       "      <td>776</td>\n",
       "      <td>736</td>\n",
       "      <td>682</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">jazz</th>\n",
       "      <th>words</th>\n",
       "      <td>love</td>\n",
       "      <td>im</td>\n",
       "      <td>dont</td>\n",
       "      <td>know</td>\n",
       "      <td>?</td>\n",
       "      <td>baby</td>\n",
       "      <td>like</td>\n",
       "      <td>let</td>\n",
       "      <td>come</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>490</td>\n",
       "      <td>351</td>\n",
       "      <td>284</td>\n",
       "      <td>231</td>\n",
       "      <td>223</td>\n",
       "      <td>220</td>\n",
       "      <td>206</td>\n",
       "      <td>184</td>\n",
       "      <td>182</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">metal</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>?</td>\n",
       "      <td>!</td>\n",
       "      <td>cant</td>\n",
       "      <td>dont</td>\n",
       "      <td>see</td>\n",
       "      <td>never</td>\n",
       "      <td>one</td>\n",
       "      <td>like</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>1644</td>\n",
       "      <td>1464</td>\n",
       "      <td>1462</td>\n",
       "      <td>887</td>\n",
       "      <td>874</td>\n",
       "      <td>791</td>\n",
       "      <td>774</td>\n",
       "      <td>760</td>\n",
       "      <td>745</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">pop</th>\n",
       "      <th>words</th>\n",
       "      <td>thats</td>\n",
       "      <td>man</td>\n",
       "      <td>take</td>\n",
       "      <td>im</td>\n",
       "      <td>wreck</td>\n",
       "      <td>plans</td>\n",
       "      <td>hand</td>\n",
       "      <td>begging</td>\n",
       "      <td>know</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">punk</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>?</td>\n",
       "      <td>dont</td>\n",
       "      <td>know</td>\n",
       "      <td>like</td>\n",
       "      <td>oh</td>\n",
       "      <td>youre</td>\n",
       "      <td>!</td>\n",
       "      <td>go</td>\n",
       "      <td>never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>1619</td>\n",
       "      <td>1181</td>\n",
       "      <td>1025</td>\n",
       "      <td>843</td>\n",
       "      <td>779</td>\n",
       "      <td>764</td>\n",
       "      <td>669</td>\n",
       "      <td>590</td>\n",
       "      <td>575</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rnb</th>\n",
       "      <th>words</th>\n",
       "      <td>love</td>\n",
       "      <td>oh</td>\n",
       "      <td>yeah</td>\n",
       "      <td>im</td>\n",
       "      <td>baby</td>\n",
       "      <td>dont</td>\n",
       "      <td>know</td>\n",
       "      <td>like</td>\n",
       "      <td>?</td>\n",
       "      <td>youre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>1871</td>\n",
       "      <td>1817</td>\n",
       "      <td>1779</td>\n",
       "      <td>1612</td>\n",
       "      <td>1407</td>\n",
       "      <td>1394</td>\n",
       "      <td>1374</td>\n",
       "      <td>1166</td>\n",
       "      <td>1104</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rock</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>?</td>\n",
       "      <td>dont</td>\n",
       "      <td>oh</td>\n",
       "      <td>like</td>\n",
       "      <td>know</td>\n",
       "      <td>yeah</td>\n",
       "      <td>time</td>\n",
       "      <td>love</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>3547</td>\n",
       "      <td>2629</td>\n",
       "      <td>2580</td>\n",
       "      <td>2502</td>\n",
       "      <td>1964</td>\n",
       "      <td>1889</td>\n",
       "      <td>1689</td>\n",
       "      <td>1480</td>\n",
       "      <td>1472</td>\n",
       "      <td>1416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">romance</th>\n",
       "      <th>words</th>\n",
       "      <td>love</td>\n",
       "      <td>im</td>\n",
       "      <td>know</td>\n",
       "      <td>oh</td>\n",
       "      <td>baby</td>\n",
       "      <td>ill</td>\n",
       "      <td>dont</td>\n",
       "      <td>?</td>\n",
       "      <td>time</td>\n",
       "      <td>youre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>1135</td>\n",
       "      <td>618</td>\n",
       "      <td>596</td>\n",
       "      <td>496</td>\n",
       "      <td>473</td>\n",
       "      <td>459</td>\n",
       "      <td>450</td>\n",
       "      <td>408</td>\n",
       "      <td>398</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">soul</th>\n",
       "      <th>words</th>\n",
       "      <td>love</td>\n",
       "      <td>oh</td>\n",
       "      <td>baby</td>\n",
       "      <td>dont</td>\n",
       "      <td>know</td>\n",
       "      <td>im</td>\n",
       "      <td>yeah</td>\n",
       "      <td>?</td>\n",
       "      <td>like</td>\n",
       "      <td>get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>1689</td>\n",
       "      <td>1210</td>\n",
       "      <td>1194</td>\n",
       "      <td>1105</td>\n",
       "      <td>1058</td>\n",
       "      <td>1023</td>\n",
       "      <td>1016</td>\n",
       "      <td>819</td>\n",
       "      <td>650</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          1     2     3      4      5      6      7        8   \\\n",
       "blues     words           im  baby  dont   love   know    got     oh        ?   \n",
       "          frequencies    968   809   768    644    640    640    486      455   \n",
       "classical words           im   one  come   love      !   dont    get        ?   \n",
       "          frequencies    126   109   105     96     89     87     86       74   \n",
       "country   words           im  like  dont   love    got   yeah   know       oh   \n",
       "          frequencies   3013  2460  2382   2025   1959   1935   1908     1887   \n",
       "funk      words          get     !  baby   love   dont     oh     im     yeah   \n",
       "          frequencies    986   820   814    783    772    746    680      679   \n",
       "hiphop    words           im  like  yeah  nigga    got   dont      ?      get   \n",
       "          frequencies   5176  3895  3749   3248   2823   2722   2676     2399   \n",
       "indie_alt words           im    oh     ?   dont   know   like   love    youre   \n",
       "          frequencies   1555  1294  1288   1177   1026    905    776      736   \n",
       "jazz      words         love    im  dont   know      ?   baby   like      let   \n",
       "          frequencies    490   351   284    231    223    220    206      184   \n",
       "metal     words           im     ?     !   cant   dont    see  never      one   \n",
       "          frequencies   1644  1464  1462    887    874    791    774      760   \n",
       "pop       words        thats   man  take     im  wreck  plans   hand  begging   \n",
       "          frequencies     13    13    11     10      8      8      8        8   \n",
       "punk      words           im     ?  dont   know   like     oh  youre        !   \n",
       "          frequencies   1619  1181  1025    843    779    764    669      590   \n",
       "rnb       words         love    oh  yeah     im   baby   dont   know     like   \n",
       "          frequencies   1871  1817  1779   1612   1407   1394   1374     1166   \n",
       "rock      words           im     ?  dont     oh   like   know   yeah     time   \n",
       "          frequencies   3547  2629  2580   2502   1964   1889   1689     1480   \n",
       "romance   words         love    im  know     oh   baby    ill   dont        ?   \n",
       "          frequencies   1135   618   596    496    473    459    450      408   \n",
       "soul      words         love    oh  baby   dont   know     im   yeah        ?   \n",
       "          frequencies   1689  1210  1194   1105   1058   1023   1016      819   \n",
       "\n",
       "                         9      10  \n",
       "blues     words        well    man  \n",
       "          frequencies   374    350  \n",
       "classical words        know   like  \n",
       "          frequencies    73     71  \n",
       "country   words        aint      ?  \n",
       "          frequencies  1712   1645  \n",
       "funk      words         got      ?  \n",
       "          frequencies   638    632  \n",
       "hiphop    words        know   aint  \n",
       "          frequencies  2317   2036  \n",
       "indie_alt words        time    ooh  \n",
       "          frequencies   682    623  \n",
       "jazz      words        come   time  \n",
       "          frequencies   182    181  \n",
       "metal     words        like   know  \n",
       "          frequencies   745    710  \n",
       "pop       words        know   like  \n",
       "          frequencies     7      7  \n",
       "punk      words          go  never  \n",
       "          frequencies   575    574  \n",
       "rnb       words           ?  youre  \n",
       "          frequencies  1104    794  \n",
       "rock      words        love     go  \n",
       "          frequencies  1472   1416  \n",
       "romance   words        time  youre  \n",
       "          frequencies   398    359  \n",
       "soul      words        like    get  \n",
       "          frequencies   650    630  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame of top ten words\n",
    "categories = np.array(['blues', 'blues', 'classical', 'classical', 'country', 'country', 'funk', \n",
    "              'funk', 'hiphop', 'hiphop', 'indie_alt', 'indie_alt', 'jazz', 'jazz', 'metal',\n",
    "              'metal', 'pop', 'pop', 'punk', 'punk', 'rnb', 'rnb', 'rock', 'rock', \n",
    "              'romance', 'romance', 'soul', 'soul'])\n",
    "arrays = [categories, np.array(['words', 'frequencies', 'words', 'frequencies', 'words', \n",
    "                       'frequencies', 'words', 'frequencies', 'words', 'frequencies', \n",
    "                       'words', 'frequencies', 'words', 'frequencies', 'words',\n",
    "                       'frequencies', 'words', 'frequencies', 'words', 'frequencies', \n",
    "                       'words', 'frequencies', 'words', 'frequencies', 'words', \n",
    "                       'frequencies', 'words', 'frequencies'])]\n",
    "tuples = list(zip(*arrays))\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['genre', 'w/f'])\n",
    "top_ten = pd.DataFrame(df_rows, index=arrays, columns=range(1,11))\n",
    "top_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV\n",
    "top_ten.to_csv('../Data/top_words.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions about top words\n",
    "- From the total 140 top ten words from each of the 14 genres, 29 were unique\n",
    "- 7 out of all the top ten words for each genre are unique to one genre\n",
    "    - 'cant' is unique to the top words in the metal genre\n",
    "    - 'let' is unique to the top words in the jazz genre\n",
    "    - 'nigga' is unique to the hiphop genre\n",
    "    - 'man' and 'well' are unique to the blues genre\n",
    "    - 'see' is unique to the top words in the metal genre\n",
    "    - 'ill' is unique to the top words in the romance genre\n",
    "- 6 out of all the top ten words for each genre are unique to two genre\n",
    "    - 'go' is unique to the top words in the punk and rock genres\n",
    "    - 'aint' is unique to the top words in the country and hiphop genres\n",
    "    - 'come' is unique to the top words in the classical and jazz genres\n",
    "    - 'ooh' is unique to the top words in the indie-alt and pop genres\n",
    "    - 'one' isunique to the top words in the classical and metal genres\n",
    "    - 'never' is unique to the top words in the metal and punk genres\n",
    "- '?', 'dont', and 'im' are in the top ten words for every genre\n",
    "    - 'know' is in the top ten words for every genre except funk\n",
    "    - 'like' and 'love are in the top ten words for 11 out of 14 genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
