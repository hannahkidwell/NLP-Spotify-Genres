{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 36.347357988357544 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>category_id</th>\n",
       "      <th>genre_list</th>\n",
       "      <th>audio_ft_danceability</th>\n",
       "      <th>audio_ft_energy</th>\n",
       "      <th>audio_ft_key</th>\n",
       "      <th>audio_ft_mode</th>\n",
       "      <th>audio_ft_speechiness</th>\n",
       "      <th>...</th>\n",
       "      <th>professed</th>\n",
       "      <th>plottin</th>\n",
       "      <th>sideline</th>\n",
       "      <th>sufficient</th>\n",
       "      <th>girly</th>\n",
       "      <th>reek</th>\n",
       "      <th>duffel</th>\n",
       "      <th>bitter</th>\n",
       "      <th>staff</th>\n",
       "      <th>eighth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-2</th>\n",
       "      <td>8042</td>\n",
       "      <td>8042</td>\n",
       "      <td>8042</td>\n",
       "      <td>7618.0</td>\n",
       "      <td>8042</td>\n",
       "      <td>8042.0000</td>\n",
       "      <td>8042.0000</td>\n",
       "      <td>7175.0</td>\n",
       "      <td>5518.0</td>\n",
       "      <td>8042.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53468.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4528.6433</td>\n",
       "      <td>5362.4272</td>\n",
       "      <td>42651.0</td>\n",
       "      <td>5517.0</td>\n",
       "      <td>665.7547</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>willow</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>pop</td>\n",
       "      <td>8.0</td>\n",
       "      <td>['dance', 'pop']</td>\n",
       "      <td>0.3920</td>\n",
       "      <td>0.5740</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 12086 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_name   artist_name category_name  category_id        genre_list  \\\n",
       "-2      8042          8042          8042       7618.0              8042   \n",
       "-1       NaN           NaN           NaN      53468.0               NaN   \n",
       "0     willow  Taylor Swift           pop          8.0  ['dance', 'pop']   \n",
       "\n",
       "    audio_ft_danceability  audio_ft_energy  audio_ft_key  audio_ft_mode  \\\n",
       "-2              8042.0000        8042.0000        7175.0         5518.0   \n",
       "-1              4528.6433        5362.4272       42651.0         5517.0   \n",
       "0                  0.3920           0.5740           7.0            1.0   \n",
       "\n",
       "    audio_ft_speechiness  ...  professed  plottin  sideline  sufficient  \\\n",
       "-2             8042.0000  ...        4.0      9.0       4.0         5.0   \n",
       "-1              665.7547  ...        4.0     12.0       6.0         4.0   \n",
       "0                 0.1700  ...        0.0      0.0       0.0         0.0   \n",
       "\n",
       "    girly  reek  duffel  bitter  staff  eighth  \n",
       "-2    4.0   7.0     4.0    90.0    9.0     6.0  \n",
       "-1   14.0   6.0    13.0   143.0   12.0     5.0  \n",
       "0     0.0   0.0     0.0     0.0    0.0     0.0  \n",
       "\n",
       "[3 rows x 12086 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame from CSV\n",
    "t0 = time.time()\n",
    "filtered_lyric_TF_df = pd.read_csv('../../Data/filtered_lyric_TF.csv')\n",
    "filtered_lyric_TF_df.index = filtered_lyric_TF_df.index - 2\n",
    "t1 = time.time()\n",
    "print(f'Run time: {t1-t0} seconds')\n",
    "filtered_lyric_TF_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blues 0.0\n",
      "classical 1.0\n",
      "country 2.0\n",
      "funk 3.0\n",
      "hiphop 4.0\n",
      "indie_alt 5.0\n",
      "jazz 6.0\n",
      "metal 7.0\n",
      "pop 8.0\n",
      "punk 9.0\n",
      "rnb 10.0\n",
      "rock 11.0\n",
      "romance 12.0\n",
      "soul 13.0\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary of category names and ids\n",
    "cat_name_id = {}\n",
    "category_list = ['blues', 'classical', 'country', 'funk', 'hiphop', 'indie_alt', 'jazz', \n",
    "                 'metal', 'pop', 'punk', 'rnb', 'rock', 'romance', 'soul']\n",
    "for cat in category_list:\n",
    "    cat_id = list(filtered_lyric_TF_df[filtered_lyric_TF_df['category_name']==cat]['category_id'])[0]\n",
    "    cat_name_id[cat] = cat_id\n",
    "    print(cat, cat_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame and combine the columns for the singular and plural n-word\n",
    "new_lyric_TF_df = filtered_lyric_TF_df.drop([-2, -1])\n",
    "for i in range(len(new_lyric_TF_df)):\n",
    "    new_lyric_TF_df.at[i, 'nigga'] = new_lyric_TF_df.at[i, 'nigga'] + new_lyric_TF_df.at[i, 'niggas']\n",
    "new_lyric_TF_df = new_lyric_TF_df.drop('niggas', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'im': 25268.0,\n",
       " 'dont': 17926.0,\n",
       " '?': 16660.0,\n",
       " 'like': 16025.0,\n",
       " 'know': 15042.0,\n",
       " 'oh': 15001.0,\n",
       " 'yeah': 14831.0,\n",
       " 'love': 14136.0,\n",
       " 'got': 11286.0,\n",
       " 'get': 10845.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of the overall top ten words \n",
    "word_count_df = filtered_lyric_TF_df[1:2][filtered_lyric_TF_df.columns[17:]]\n",
    "word_count_df = word_count_df.sort_values(by=[-1], axis=1, ascending=False)\n",
    "top_word_counts = list(word_count_df.loc[-1])[0:10]\n",
    "top_ten = dict(zip(list(word_count_df)[0:10], top_word_counts))\n",
    "top_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blues': {'im': 968.0,\n",
       "  'baby': 809.0,\n",
       "  'dont': 769.0,\n",
       "  'love': 645.0,\n",
       "  'got': 645.0,\n",
       "  'know': 640.0,\n",
       "  'oh': 486.0,\n",
       "  '?': 459.0,\n",
       "  'well': 374.0,\n",
       "  'man': 350.0},\n",
       " 'classical': {'!': 146.0,\n",
       "  'im': 131.0,\n",
       "  'one': 118.0,\n",
       "  'love': 111.0,\n",
       "  'come': 107.0,\n",
       "  'dont': 96.0,\n",
       "  'da': 96.0,\n",
       "  '?': 93.0,\n",
       "  'get': 86.0,\n",
       "  'know': 76.0},\n",
       " 'country': {'im': 3013.0,\n",
       "  'like': 2460.0,\n",
       "  'dont': 2382.0,\n",
       "  'love': 2025.0,\n",
       "  'got': 1959.0,\n",
       "  'yeah': 1935.0,\n",
       "  'know': 1908.0,\n",
       "  'oh': 1887.0,\n",
       "  'aint': 1712.0,\n",
       "  '?': 1645.0},\n",
       " 'funk': {'get': 986.0,\n",
       "  '!': 832.0,\n",
       "  'baby': 814.0,\n",
       "  'love': 783.0,\n",
       "  'dont': 772.0,\n",
       "  'oh': 746.0,\n",
       "  'im': 680.0,\n",
       "  'yeah': 679.0,\n",
       "  'got': 638.0,\n",
       "  '?': 632.0},\n",
       " 'hiphop': {'im': 5155.0,\n",
       "  'like': 3891.0,\n",
       "  'yeah': 3766.0,\n",
       "  'nigga': 3247.0,\n",
       "  'got': 2819.0,\n",
       "  'dont': 2723.0,\n",
       "  '?': 2676.0,\n",
       "  'get': 2397.0,\n",
       "  'know': 2316.0,\n",
       "  'aint': 2036.0},\n",
       " 'indie_alt': {'im': 1556.0,\n",
       "  '?': 1305.0,\n",
       "  'oh': 1300.0,\n",
       "  'dont': 1177.0,\n",
       "  'know': 1026.0,\n",
       "  'like': 911.0,\n",
       "  'love': 776.0,\n",
       "  'youre': 737.0,\n",
       "  'time': 682.0,\n",
       "  'ooh': 623.0},\n",
       " 'jazz': {'love': 490.0,\n",
       "  'im': 351.0,\n",
       "  'dont': 286.0,\n",
       "  'know': 233.0,\n",
       "  '?': 225.0,\n",
       "  'baby': 220.0,\n",
       "  'like': 206.0,\n",
       "  'let': 184.0,\n",
       "  'come': 182.0,\n",
       "  'time': 181.0},\n",
       " 'metal': {'im': 1645.0,\n",
       "  '?': 1476.0,\n",
       "  '!': 1471.0,\n",
       "  'cant': 893.0,\n",
       "  'dont': 877.0,\n",
       "  'see': 794.0,\n",
       "  'never': 775.0,\n",
       "  'one': 762.0,\n",
       "  'like': 746.0,\n",
       "  'know': 710.0},\n",
       " 'pop': {'thats': 13.0,\n",
       "  'man': 13.0,\n",
       "  'take': 11.0,\n",
       "  'im': 9.0,\n",
       "  'wreck': 8.0,\n",
       "  'plans': 8.0,\n",
       "  'begging': 8.0,\n",
       "  'hand': 8.0,\n",
       "  'know': 7.0,\n",
       "  'wherever': 4.0},\n",
       " 'punk': {'im': 1619.0,\n",
       "  '?': 1181.0,\n",
       "  'dont': 1025.0,\n",
       "  'know': 843.0,\n",
       "  'like': 779.0,\n",
       "  'oh': 764.0,\n",
       "  'youre': 669.0,\n",
       "  '!': 590.0,\n",
       "  'go': 575.0,\n",
       "  'never': 574.0},\n",
       " 'rnb': {'love': 1871.0,\n",
       "  'oh': 1817.0,\n",
       "  'yeah': 1779.0,\n",
       "  'im': 1612.0,\n",
       "  'baby': 1407.0,\n",
       "  'dont': 1394.0,\n",
       "  'know': 1374.0,\n",
       "  'like': 1166.0,\n",
       "  '?': 1104.0,\n",
       "  'youre': 794.0},\n",
       " 'rock': {'im': 3547.0,\n",
       "  '?': 2629.0,\n",
       "  'dont': 2580.0,\n",
       "  'oh': 2502.0,\n",
       "  'like': 1964.0,\n",
       "  'know': 1889.0,\n",
       "  'yeah': 1689.0,\n",
       "  'time': 1480.0,\n",
       "  'love': 1472.0,\n",
       "  'go': 1416.0},\n",
       " 'romance': {'love': 1135.0,\n",
       "  'im': 618.0,\n",
       "  'know': 596.0,\n",
       "  'oh': 496.0,\n",
       "  'baby': 473.0,\n",
       "  'ill': 459.0,\n",
       "  'dont': 450.0,\n",
       "  '?': 408.0,\n",
       "  'time': 398.0,\n",
       "  'youre': 359.0},\n",
       " 'soul': {'love': 1689.0,\n",
       "  'oh': 1210.0,\n",
       "  'baby': 1194.0,\n",
       "  'dont': 1105.0,\n",
       "  'know': 1058.0,\n",
       "  'im': 1023.0,\n",
       "  'yeah': 1016.0,\n",
       "  '?': 819.0,\n",
       "  'like': 650.0,\n",
       "  'get': 630.0}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the top words for each category\n",
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of the top ten words for each category\n",
    "t0 = time.time()\n",
    "top_words = {}\n",
    "df_rows = []\n",
    "blues_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='blues'].copy()\n",
    "blues_df.loc[0] = blues_df.sum(numeric_only=True)\n",
    "blues_words = blues_df.sort_index()[blues_df.columns[17:]][0:1]\n",
    "blues_words = blues_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(blues_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(blues_words)[0:10], top_word_counts))\n",
    "top_words['blues'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "classical_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='classical'].copy()\n",
    "classical_df.loc[0] = classical_df.sum(numeric_only=True)\n",
    "classical_words = classical_df.sort_index()[classical_df.columns[17:]][0:1]\n",
    "classical_words = classical_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(classical_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(classical_words), top_word_counts))\n",
    "top_words['classical'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "country_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='country'].copy()\n",
    "country_df.loc[0] = country_df.sum(numeric_only=True)\n",
    "country_words = country_df.sort_index()[country_df.columns[17:]][0:1]\n",
    "country_words = country_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(country_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(country_words)[0:10], top_word_counts))\n",
    "top_words['country'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "funk_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='funk'].copy()\n",
    "funk_df.loc[0] = funk_df.sum(numeric_only=True)\n",
    "funk_words = funk_df.sort_index()[funk_df.columns[17:]][0:1]\n",
    "funk_words = funk_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(funk_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(funk_words)[0:10], top_word_counts))\n",
    "top_words['funk'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "hiphop_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='hiphop'].copy()\n",
    "hiphop_df.loc[0] = hiphop_df.sum(numeric_only=True)\n",
    "hiphop_words = hiphop_df.sort_index()[hiphop_df.columns[17:]][0:1]\n",
    "hiphop_words = hiphop_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(hiphop_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(hiphop_words)[0:10], top_word_counts))\n",
    "top_words['hiphop'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "indie_alt_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='indie_alt'].copy()\n",
    "indie_alt_df.loc[0] = indie_alt_df.sum(numeric_only=True)\n",
    "indie_alt_words = indie_alt_df.sort_index()[indie_alt_df.columns[17:]][0:1]\n",
    "indie_alt_words = indie_alt_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(indie_alt_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(indie_alt_words)[0:10], top_word_counts))\n",
    "top_words['indie_alt'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "jazz_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='jazz'].copy()\n",
    "jazz_df.loc[0] = jazz_df.sum(numeric_only=True)\n",
    "jazz_words = jazz_df.sort_index()[jazz_df.columns[17:]][0:1]\n",
    "jazz_words = jazz_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(jazz_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(jazz_words)[0:10], top_word_counts))\n",
    "top_words['jazz'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "metal_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='metal'].copy()\n",
    "metal_df.loc[0] = metal_df.sum(numeric_only=True)\n",
    "metal_words = metal_df.sort_index()[metal_df.columns[17:]][0:1]\n",
    "metal_words = metal_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(metal_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(metal_words)[0:10], top_word_counts))\n",
    "top_words['metal'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "pop_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='pop'].copy()\n",
    "pop_df.loc[-1] = pop_df.sum(numeric_only=True)\n",
    "pop_words = pop_df.sort_index()[pop_df.columns[17:]]\n",
    "pop_words = pop_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(pop_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(pop_words)[0:10], top_word_counts))\n",
    "top_words['pop'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "punk_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='punk'].copy()\n",
    "punk_df.loc[0] = punk_df.sum(numeric_only=True)\n",
    "punk_words = punk_df.sort_index()[punk_df.columns[17:]][0:1]\n",
    "punk_words = punk_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(punk_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(punk_words)[0:10], top_word_counts))\n",
    "top_words['punk'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "rnb_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='rnb'].copy()\n",
    "rnb_df.loc[0] = rnb_df.sum(numeric_only=True)\n",
    "rnb_words = rnb_df.sort_index()[rnb_df.columns[17:]][0:1]\n",
    "rnb_words = rnb_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(rnb_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(rnb_words)[0:10], top_word_counts))\n",
    "top_words['rnb'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "rock_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='rock'].copy()\n",
    "rock_df.loc[0] = rock_df.sum(numeric_only=True)\n",
    "rock_words = rock_df.sort_index()[rock_df.columns[17:]][0:1]\n",
    "rock_words = rock_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(rock_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(rock_words)[0:10], top_word_counts))\n",
    "top_words['rock'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "romance_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='romance'].copy()\n",
    "romance_df.loc[0] = romance_df.sum(numeric_only=True)\n",
    "romance_words = romance_df.sort_index()[romance_df.columns[17:]][0:1]\n",
    "romance_words = romance_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(romance_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(romance_words)[0:10], top_word_counts))\n",
    "top_words['romance'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "soul_df = new_lyric_TF_df[new_lyric_TF_df['category_name']=='soul'].copy()\n",
    "soul_df.loc[0] = soul_df.sum(numeric_only=True)\n",
    "soul_words = soul_df.sort_index()[soul_df.columns[17:]][0:1]\n",
    "soul_words = soul_words.sort_values(by=[0], axis=1, ascending=False)\n",
    "top_word_counts = list(soul_words.loc[0])[0:10]\n",
    "top_ten = dict(zip(list(soul_words)[0:10], top_word_counts))\n",
    "top_words['soul'] = top_ten\n",
    "df_rows.append(list(top_ten.keys()))\n",
    "df_rows.append(list(top_ten.values()))\n",
    "\n",
    "t1 = time.time()\n",
    "print(f'Run time: {t1-t0} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blues': {'im': 968.0,\n",
       "  'baby': 809.0,\n",
       "  'dont': 769.0,\n",
       "  'love': 645.0,\n",
       "  'got': 645.0,\n",
       "  'know': 640.0,\n",
       "  'oh': 486.0,\n",
       "  '?': 459.0,\n",
       "  'well': 374.0,\n",
       "  'man': 350.0},\n",
       " 'classical': {'!': 146.0,\n",
       "  'im': 131.0,\n",
       "  'one': 118.0,\n",
       "  'love': 111.0,\n",
       "  'come': 107.0,\n",
       "  'dont': 96.0,\n",
       "  'da': 96.0,\n",
       "  '?': 93.0,\n",
       "  'get': 86.0,\n",
       "  'know': 76.0},\n",
       " 'country': {'im': 3013.0,\n",
       "  'like': 2460.0,\n",
       "  'dont': 2382.0,\n",
       "  'love': 2025.0,\n",
       "  'got': 1959.0,\n",
       "  'yeah': 1935.0,\n",
       "  'know': 1908.0,\n",
       "  'oh': 1887.0,\n",
       "  'aint': 1712.0,\n",
       "  '?': 1645.0},\n",
       " 'funk': {'get': 986.0,\n",
       "  '!': 832.0,\n",
       "  'baby': 814.0,\n",
       "  'love': 783.0,\n",
       "  'dont': 772.0,\n",
       "  'oh': 746.0,\n",
       "  'im': 680.0,\n",
       "  'yeah': 679.0,\n",
       "  'got': 638.0,\n",
       "  '?': 632.0},\n",
       " 'hiphop': {'im': 5155.0,\n",
       "  'like': 3891.0,\n",
       "  'yeah': 3766.0,\n",
       "  'nigga': 3247.0,\n",
       "  'got': 2819.0,\n",
       "  'dont': 2723.0,\n",
       "  '?': 2676.0,\n",
       "  'get': 2397.0,\n",
       "  'know': 2316.0,\n",
       "  'aint': 2036.0},\n",
       " 'indie_alt': {'im': 1556.0,\n",
       "  '?': 1305.0,\n",
       "  'oh': 1300.0,\n",
       "  'dont': 1177.0,\n",
       "  'know': 1026.0,\n",
       "  'like': 911.0,\n",
       "  'love': 776.0,\n",
       "  'youre': 737.0,\n",
       "  'time': 682.0,\n",
       "  'ooh': 623.0},\n",
       " 'jazz': {'love': 490.0,\n",
       "  'im': 351.0,\n",
       "  'dont': 286.0,\n",
       "  'know': 233.0,\n",
       "  '?': 225.0,\n",
       "  'baby': 220.0,\n",
       "  'like': 206.0,\n",
       "  'let': 184.0,\n",
       "  'come': 182.0,\n",
       "  'time': 181.0},\n",
       " 'metal': {'im': 1645.0,\n",
       "  '?': 1476.0,\n",
       "  '!': 1471.0,\n",
       "  'cant': 893.0,\n",
       "  'dont': 877.0,\n",
       "  'see': 794.0,\n",
       "  'never': 775.0,\n",
       "  'one': 762.0,\n",
       "  'like': 746.0,\n",
       "  'know': 710.0},\n",
       " 'pop': {'thats': 13.0,\n",
       "  'man': 13.0,\n",
       "  'take': 11.0,\n",
       "  'im': 9.0,\n",
       "  'wreck': 8.0,\n",
       "  'plans': 8.0,\n",
       "  'begging': 8.0,\n",
       "  'hand': 8.0,\n",
       "  'know': 7.0,\n",
       "  'wherever': 4.0},\n",
       " 'punk': {'im': 1619.0,\n",
       "  '?': 1181.0,\n",
       "  'dont': 1025.0,\n",
       "  'know': 843.0,\n",
       "  'like': 779.0,\n",
       "  'oh': 764.0,\n",
       "  'youre': 669.0,\n",
       "  '!': 590.0,\n",
       "  'go': 575.0,\n",
       "  'never': 574.0},\n",
       " 'rnb': {'love': 1871.0,\n",
       "  'oh': 1817.0,\n",
       "  'yeah': 1779.0,\n",
       "  'im': 1612.0,\n",
       "  'baby': 1407.0,\n",
       "  'dont': 1394.0,\n",
       "  'know': 1374.0,\n",
       "  'like': 1166.0,\n",
       "  '?': 1104.0,\n",
       "  'youre': 794.0},\n",
       " 'rock': {'im': 3547.0,\n",
       "  '?': 2629.0,\n",
       "  'dont': 2580.0,\n",
       "  'oh': 2502.0,\n",
       "  'like': 1964.0,\n",
       "  'know': 1889.0,\n",
       "  'yeah': 1689.0,\n",
       "  'time': 1480.0,\n",
       "  'love': 1472.0,\n",
       "  'go': 1416.0},\n",
       " 'romance': {'love': 1135.0,\n",
       "  'im': 618.0,\n",
       "  'know': 596.0,\n",
       "  'oh': 496.0,\n",
       "  'baby': 473.0,\n",
       "  'ill': 459.0,\n",
       "  'dont': 450.0,\n",
       "  '?': 408.0,\n",
       "  'time': 398.0,\n",
       "  'youre': 359.0},\n",
       " 'soul': {'love': 1689.0,\n",
       "  'oh': 1210.0,\n",
       "  'baby': 1194.0,\n",
       "  'dont': 1105.0,\n",
       "  'know': 1058.0,\n",
       "  'im': 1023.0,\n",
       "  'yeah': 1016.0,\n",
       "  '?': 819.0,\n",
       "  'like': 650.0,\n",
       "  'get': 630.0}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the top words for each category\n",
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'begging': 1,\n",
       " '?': 13,\n",
       " 'hand': 1,\n",
       " 'got': 4,\n",
       " 'know': 13,\n",
       " 'well': 1,\n",
       " 'aint': 2,\n",
       " '!': 4,\n",
       " 'wherever': 1,\n",
       " 'love': 10,\n",
       " 'dont': 13,\n",
       " 'go': 2,\n",
       " 'da': 1,\n",
       " 'thats': 1,\n",
       " 'ill': 1,\n",
       " 'like': 9,\n",
       " 'cant': 1,\n",
       " 'im': 14,\n",
       " 'get': 4,\n",
       " 'baby': 6,\n",
       " 'come': 2,\n",
       " 'yeah': 6,\n",
       " 'oh': 9,\n",
       " 'one': 2,\n",
       " 'youre': 4,\n",
       " 'plans': 1,\n",
       " 'let': 1,\n",
       " 'man': 2,\n",
       " 'time': 4,\n",
       " 'see': 1,\n",
       " 'never': 2,\n",
       " 'wreck': 1,\n",
       " 'nigga': 1,\n",
       " 'take': 1,\n",
       " 'ooh': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary of top word frequencies\n",
    "unique_top_words = []\n",
    "for category in top_words:\n",
    "    unique_top_words.extend(top_words[category])\n",
    "unique_top_words = list(set(unique_top_words))\n",
    "\n",
    "top_word_freq = dict.fromkeys(unique_top_words, 0)\n",
    "for category in top_words:\n",
    "    for word in top_words[category]:\n",
    "        top_word_freq[word]+=1\n",
    "print(len(top_word_freq))\n",
    "top_word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'begging': 1,\n",
       " 'hand': 1,\n",
       " 'well': 1,\n",
       " 'wherever': 1,\n",
       " 'da': 1,\n",
       " 'thats': 1,\n",
       " 'ill': 1,\n",
       " 'cant': 1,\n",
       " 'plans': 1,\n",
       " 'let': 1,\n",
       " 'see': 1,\n",
       " 'wreck': 1,\n",
       " 'nigga': 1,\n",
       " 'take': 1,\n",
       " 'ooh': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print top words that are unique to one genre\n",
    "dict(filter(lambda key: key[1] == 1, top_word_freq.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aint': 2, 'go': 2, 'come': 2, 'one': 2, 'man': 2, 'never': 2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print top words that are unique to two genres\n",
    "dict(filter(lambda key: key[1] == 2, top_word_freq.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">blues</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>baby</td>\n",
       "      <td>dont</td>\n",
       "      <td>love</td>\n",
       "      <td>got</td>\n",
       "      <td>know</td>\n",
       "      <td>oh</td>\n",
       "      <td>?</td>\n",
       "      <td>well</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>968</td>\n",
       "      <td>809</td>\n",
       "      <td>769</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>640</td>\n",
       "      <td>486</td>\n",
       "      <td>459</td>\n",
       "      <td>374</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">classical</th>\n",
       "      <th>words</th>\n",
       "      <td>!</td>\n",
       "      <td>im</td>\n",
       "      <td>one</td>\n",
       "      <td>love</td>\n",
       "      <td>come</td>\n",
       "      <td>dont</td>\n",
       "      <td>da</td>\n",
       "      <td>?</td>\n",
       "      <td>get</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>146</td>\n",
       "      <td>131</td>\n",
       "      <td>118</td>\n",
       "      <td>111</td>\n",
       "      <td>107</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>93</td>\n",
       "      <td>86</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">country</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>like</td>\n",
       "      <td>dont</td>\n",
       "      <td>love</td>\n",
       "      <td>got</td>\n",
       "      <td>yeah</td>\n",
       "      <td>know</td>\n",
       "      <td>oh</td>\n",
       "      <td>aint</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>3013</td>\n",
       "      <td>2460</td>\n",
       "      <td>2382</td>\n",
       "      <td>2025</td>\n",
       "      <td>1959</td>\n",
       "      <td>1935</td>\n",
       "      <td>1908</td>\n",
       "      <td>1887</td>\n",
       "      <td>1712</td>\n",
       "      <td>1645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">funk</th>\n",
       "      <th>words</th>\n",
       "      <td>get</td>\n",
       "      <td>!</td>\n",
       "      <td>baby</td>\n",
       "      <td>love</td>\n",
       "      <td>dont</td>\n",
       "      <td>oh</td>\n",
       "      <td>im</td>\n",
       "      <td>yeah</td>\n",
       "      <td>got</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>986</td>\n",
       "      <td>832</td>\n",
       "      <td>814</td>\n",
       "      <td>783</td>\n",
       "      <td>772</td>\n",
       "      <td>746</td>\n",
       "      <td>680</td>\n",
       "      <td>679</td>\n",
       "      <td>638</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">hiphop</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>like</td>\n",
       "      <td>yeah</td>\n",
       "      <td>nigga</td>\n",
       "      <td>got</td>\n",
       "      <td>dont</td>\n",
       "      <td>?</td>\n",
       "      <td>get</td>\n",
       "      <td>know</td>\n",
       "      <td>aint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>5155</td>\n",
       "      <td>3891</td>\n",
       "      <td>3766</td>\n",
       "      <td>3247</td>\n",
       "      <td>2819</td>\n",
       "      <td>2723</td>\n",
       "      <td>2676</td>\n",
       "      <td>2397</td>\n",
       "      <td>2316</td>\n",
       "      <td>2036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">indie_alt</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>?</td>\n",
       "      <td>oh</td>\n",
       "      <td>dont</td>\n",
       "      <td>know</td>\n",
       "      <td>like</td>\n",
       "      <td>love</td>\n",
       "      <td>youre</td>\n",
       "      <td>time</td>\n",
       "      <td>ooh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>1556</td>\n",
       "      <td>1305</td>\n",
       "      <td>1300</td>\n",
       "      <td>1177</td>\n",
       "      <td>1026</td>\n",
       "      <td>911</td>\n",
       "      <td>776</td>\n",
       "      <td>737</td>\n",
       "      <td>682</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">jazz</th>\n",
       "      <th>words</th>\n",
       "      <td>love</td>\n",
       "      <td>im</td>\n",
       "      <td>dont</td>\n",
       "      <td>know</td>\n",
       "      <td>?</td>\n",
       "      <td>baby</td>\n",
       "      <td>like</td>\n",
       "      <td>let</td>\n",
       "      <td>come</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>490</td>\n",
       "      <td>351</td>\n",
       "      <td>286</td>\n",
       "      <td>233</td>\n",
       "      <td>225</td>\n",
       "      <td>220</td>\n",
       "      <td>206</td>\n",
       "      <td>184</td>\n",
       "      <td>182</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">metal</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>?</td>\n",
       "      <td>!</td>\n",
       "      <td>cant</td>\n",
       "      <td>dont</td>\n",
       "      <td>see</td>\n",
       "      <td>never</td>\n",
       "      <td>one</td>\n",
       "      <td>like</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>1645</td>\n",
       "      <td>1476</td>\n",
       "      <td>1471</td>\n",
       "      <td>893</td>\n",
       "      <td>877</td>\n",
       "      <td>794</td>\n",
       "      <td>775</td>\n",
       "      <td>762</td>\n",
       "      <td>746</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">pop</th>\n",
       "      <th>words</th>\n",
       "      <td>thats</td>\n",
       "      <td>man</td>\n",
       "      <td>take</td>\n",
       "      <td>im</td>\n",
       "      <td>wreck</td>\n",
       "      <td>plans</td>\n",
       "      <td>begging</td>\n",
       "      <td>hand</td>\n",
       "      <td>know</td>\n",
       "      <td>wherever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">punk</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>?</td>\n",
       "      <td>dont</td>\n",
       "      <td>know</td>\n",
       "      <td>like</td>\n",
       "      <td>oh</td>\n",
       "      <td>youre</td>\n",
       "      <td>!</td>\n",
       "      <td>go</td>\n",
       "      <td>never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>1619</td>\n",
       "      <td>1181</td>\n",
       "      <td>1025</td>\n",
       "      <td>843</td>\n",
       "      <td>779</td>\n",
       "      <td>764</td>\n",
       "      <td>669</td>\n",
       "      <td>590</td>\n",
       "      <td>575</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rnb</th>\n",
       "      <th>words</th>\n",
       "      <td>love</td>\n",
       "      <td>oh</td>\n",
       "      <td>yeah</td>\n",
       "      <td>im</td>\n",
       "      <td>baby</td>\n",
       "      <td>dont</td>\n",
       "      <td>know</td>\n",
       "      <td>like</td>\n",
       "      <td>?</td>\n",
       "      <td>youre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>1871</td>\n",
       "      <td>1817</td>\n",
       "      <td>1779</td>\n",
       "      <td>1612</td>\n",
       "      <td>1407</td>\n",
       "      <td>1394</td>\n",
       "      <td>1374</td>\n",
       "      <td>1166</td>\n",
       "      <td>1104</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rock</th>\n",
       "      <th>words</th>\n",
       "      <td>im</td>\n",
       "      <td>?</td>\n",
       "      <td>dont</td>\n",
       "      <td>oh</td>\n",
       "      <td>like</td>\n",
       "      <td>know</td>\n",
       "      <td>yeah</td>\n",
       "      <td>time</td>\n",
       "      <td>love</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>3547</td>\n",
       "      <td>2629</td>\n",
       "      <td>2580</td>\n",
       "      <td>2502</td>\n",
       "      <td>1964</td>\n",
       "      <td>1889</td>\n",
       "      <td>1689</td>\n",
       "      <td>1480</td>\n",
       "      <td>1472</td>\n",
       "      <td>1416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">romance</th>\n",
       "      <th>words</th>\n",
       "      <td>love</td>\n",
       "      <td>im</td>\n",
       "      <td>know</td>\n",
       "      <td>oh</td>\n",
       "      <td>baby</td>\n",
       "      <td>ill</td>\n",
       "      <td>dont</td>\n",
       "      <td>?</td>\n",
       "      <td>time</td>\n",
       "      <td>youre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>1135</td>\n",
       "      <td>618</td>\n",
       "      <td>596</td>\n",
       "      <td>496</td>\n",
       "      <td>473</td>\n",
       "      <td>459</td>\n",
       "      <td>450</td>\n",
       "      <td>408</td>\n",
       "      <td>398</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">soul</th>\n",
       "      <th>words</th>\n",
       "      <td>love</td>\n",
       "      <td>oh</td>\n",
       "      <td>baby</td>\n",
       "      <td>dont</td>\n",
       "      <td>know</td>\n",
       "      <td>im</td>\n",
       "      <td>yeah</td>\n",
       "      <td>?</td>\n",
       "      <td>like</td>\n",
       "      <td>get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequencies</th>\n",
       "      <td>1689</td>\n",
       "      <td>1210</td>\n",
       "      <td>1194</td>\n",
       "      <td>1105</td>\n",
       "      <td>1058</td>\n",
       "      <td>1023</td>\n",
       "      <td>1016</td>\n",
       "      <td>819</td>\n",
       "      <td>650</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          1     2     3      4      5      6        7      8   \\\n",
       "blues     words           im  baby  dont   love    got   know       oh      ?   \n",
       "          frequencies    968   809   769    645    645    640      486    459   \n",
       "classical words            !    im   one   love   come   dont       da      ?   \n",
       "          frequencies    146   131   118    111    107     96       96     93   \n",
       "country   words           im  like  dont   love    got   yeah     know     oh   \n",
       "          frequencies   3013  2460  2382   2025   1959   1935     1908   1887   \n",
       "funk      words          get     !  baby   love   dont     oh       im   yeah   \n",
       "          frequencies    986   832   814    783    772    746      680    679   \n",
       "hiphop    words           im  like  yeah  nigga    got   dont        ?    get   \n",
       "          frequencies   5155  3891  3766   3247   2819   2723     2676   2397   \n",
       "indie_alt words           im     ?    oh   dont   know   like     love  youre   \n",
       "          frequencies   1556  1305  1300   1177   1026    911      776    737   \n",
       "jazz      words         love    im  dont   know      ?   baby     like    let   \n",
       "          frequencies    490   351   286    233    225    220      206    184   \n",
       "metal     words           im     ?     !   cant   dont    see    never    one   \n",
       "          frequencies   1645  1476  1471    893    877    794      775    762   \n",
       "pop       words        thats   man  take     im  wreck  plans  begging   hand   \n",
       "          frequencies     13    13    11      9      8      8        8      8   \n",
       "punk      words           im     ?  dont   know   like     oh    youre      !   \n",
       "          frequencies   1619  1181  1025    843    779    764      669    590   \n",
       "rnb       words         love    oh  yeah     im   baby   dont     know   like   \n",
       "          frequencies   1871  1817  1779   1612   1407   1394     1374   1166   \n",
       "rock      words           im     ?  dont     oh   like   know     yeah   time   \n",
       "          frequencies   3547  2629  2580   2502   1964   1889     1689   1480   \n",
       "romance   words         love    im  know     oh   baby    ill     dont      ?   \n",
       "          frequencies   1135   618   596    496    473    459      450    408   \n",
       "soul      words         love    oh  baby   dont   know     im     yeah      ?   \n",
       "          frequencies   1689  1210  1194   1105   1058   1023     1016    819   \n",
       "\n",
       "                         9         10  \n",
       "blues     words        well       man  \n",
       "          frequencies   374       350  \n",
       "classical words         get      know  \n",
       "          frequencies    86        76  \n",
       "country   words        aint         ?  \n",
       "          frequencies  1712      1645  \n",
       "funk      words         got         ?  \n",
       "          frequencies   638       632  \n",
       "hiphop    words        know      aint  \n",
       "          frequencies  2316      2036  \n",
       "indie_alt words        time       ooh  \n",
       "          frequencies   682       623  \n",
       "jazz      words        come      time  \n",
       "          frequencies   182       181  \n",
       "metal     words        like      know  \n",
       "          frequencies   746       710  \n",
       "pop       words        know  wherever  \n",
       "          frequencies     7         4  \n",
       "punk      words          go     never  \n",
       "          frequencies   575       574  \n",
       "rnb       words           ?     youre  \n",
       "          frequencies  1104       794  \n",
       "rock      words        love        go  \n",
       "          frequencies  1472      1416  \n",
       "romance   words        time     youre  \n",
       "          frequencies   398       359  \n",
       "soul      words        like       get  \n",
       "          frequencies   650       630  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame of top ten words\n",
    "categories = np.array(['blues', 'blues', 'classical', 'classical', 'country', 'country', 'funk', \n",
    "              'funk', 'hiphop', 'hiphop', 'indie_alt', 'indie_alt', 'jazz', 'jazz', 'metal',\n",
    "              'metal', 'pop', 'pop', 'punk', 'punk', 'rnb', 'rnb', 'rock', 'rock', \n",
    "              'romance', 'romance', 'soul', 'soul'])\n",
    "arrays = [categories, np.array(['words', 'frequencies', 'words', 'frequencies', 'words', \n",
    "                       'frequencies', 'words', 'frequencies', 'words', 'frequencies', \n",
    "                       'words', 'frequencies', 'words', 'frequencies', 'words',\n",
    "                       'frequencies', 'words', 'frequencies', 'words', 'frequencies', \n",
    "                       'words', 'frequencies', 'words', 'frequencies', 'words', \n",
    "                       'frequencies', 'words', 'frequencies'])]\n",
    "tuples = list(zip(*arrays))\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['genre', 'w/f'])\n",
    "top_ten = pd.DataFrame(df_rows, index=arrays, columns=range(1,11))\n",
    "top_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV\n",
    "top_ten.to_csv('../../Data/Analysis/top_words.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions about top words\n",
    "- From the total 140 top ten words from each of the 14 genres, 35 were unique\n",
    "- 15 out of all the top ten words for each genre are unique to one genre\n",
    "- 6 out of all the top ten words for each genre are unique to two genres\n",
    "    - 'go' is unique to the punk and rock genres\n",
    "    - 'aint' is unique to the country and hiphop genres\n",
    "    - 'come' is unique to the classical and jazz genres\n",
    "    - 'ooh' is unique to the indie-alt and pop genres\n",
    "    - 'man' is unique to the blues and pop genres\n",
    "    - 'one' is unique to the classical and metal genres\n",
    "    - 'never' is unique to the metal and punk genres\n",
    "- 'im' is in the top ten words for every genre\n",
    "- '?', 'dont', and 'know' are in the top ten words for 13 out of 14 genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
